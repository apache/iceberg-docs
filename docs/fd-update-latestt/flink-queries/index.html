<!doctype html><html><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content><meta name=author content><title>Flink Queries</title>
<link href=../css/bootstrap.css rel=stylesheet><link href=../css/markdown.css rel=stylesheet><link href=../css/katex.min.css rel=stylesheet><link href=../css/iceberg-theme.css rel=stylesheet><link href=../font-awesome-4.7.0/css/font-awesome.min.css rel=stylesheet type=text/css><link href="//fonts.googleapis.com/css?family=Lato:300,400,700,300italic,400italic,700italic" rel=stylesheet type=text/css><link href=../css/termynal.css rel=stylesheet></head><body><head><script>function addAnchor(e){e.insertAdjacentHTML("beforeend",`<a href="#${e.id}" class="anchortag" ariaLabel="Anchor"> ðŸ”— </a>`)}document.addEventListener("DOMContentLoaded",function(){var e=document.querySelectorAll("h1[id], h2[id], h3[id], h4[id]");e&&e.forEach(addAnchor)})</script></head><nav class="navbar navbar-default" role=navigation><topsection><div class=navbar-fixed-top><div><button type=button class=navbar-toggle data-toggle=collapse data-target=div.sidebar>
<span class=sr-only>Toggle navigation</span>
<span class=icon-bar></span>
<span class=icon-bar></span>
<span class=icon-bar></span>
</button>
<a class="page-scroll navbar-brand" href=https://iceberg.apache.org/><img class=top-navbar-logo src=https://iceberg.apache.org/docs/fd-update-latestt//img/iceberg-logo-icon.png> Apache Iceberg</a></div><div><input type=search class=form-control id=search-input placeholder=Search... maxlength=64 data-hotkeys=s/></div><div class=versions-dropdown><span>1.4.2</span> <i class="fa fa-chevron-down"></i><div class=versions-dropdown-content><ul><li class=versions-dropdown-selection><a href=https://iceberg.apache.org/docs/fd-update-latestt/../latest>latest</a></li><li class=versions-dropdown-selection><a href=https://iceberg.apache.org/docs/fd-update-latestt/../1.4.2>1.4.2</a></li><li class=versions-dropdown-selection><a href=https://iceberg.apache.org/docs/fd-update-latestt/../1.4.1>1.4.1</a></li><li class=versions-dropdown-selection><a href=https://iceberg.apache.org/docs/fd-update-latestt/../1.4.0>1.4.0</a></li><li class=versions-dropdown-selection><a href=https://iceberg.apache.org/docs/fd-update-latestt/../1.3.1>1.3.1</a></li><li class=versions-dropdown-selection><a href=https://iceberg.apache.org/docs/fd-update-latestt/../1.3.0>1.3.0</a></li><li class=versions-dropdown-selection><a href=https://iceberg.apache.org/docs/fd-update-latestt/../1.2.1>1.2.1</a></li><li class=versions-dropdown-selection><a href=https://iceberg.apache.org/docs/fd-update-latestt/../1.2.0>1.2.0</a></li><li class=versions-dropdown-selection><a href=https://iceberg.apache.org/docs/fd-update-latestt/../1.1.0>1.1.0</a></li><li class=versions-dropdown-selection><a href=https://iceberg.apache.org/docs/fd-update-latestt/../1.0.0>1.0.0</a></li><li class=versions-dropdown-selection><a href=https://iceberg.apache.org/docs/fd-update-latestt/../0.14.1>0.14.1</a></li><li class=versions-dropdown-selection><a href=https://iceberg.apache.org/docs/fd-update-latestt/../0.14.0>0.14.0</a></li><li class=versions-dropdown-selection><a href=https://iceberg.apache.org/docs/fd-update-latestt/../0.13.2>0.13.2</a></li><li class=versions-dropdown-selection><a href=https://iceberg.apache.org/docs/fd-update-latestt/../0.13.1>0.13.1</a></li><li class=versions-dropdown-selection><a href=https://iceberg.apache.org/docs/fd-update-latestt/../0.13.0>0.13.0</a></li><li class=versions-dropdown-selection><a href=https://iceberg.apache.org/docs/fd-update-latestt/../0.12.1>0.12.1</a></li></ul></div></div></div><div class="navbar-menu-fixed-top navbar-pages-group"><div class=versions-dropdown><div class=topnav-page-selection><a href>Quickstart</a> <i class="fa fa-chevron-down"></i></div class="topnav-page-selection"><div class=versions-dropdown-content><ul><li class=topnav-page-selection><a href=https://iceberg.apache.org/docs/fd-update-latestt/../../hive-quickstart>Hive</a></li class="topnav-page-selection"><li class=topnav-page-selection><a href=https://iceberg.apache.org/docs/fd-update-latestt/../../spark-quickstart>Spark</a></li class="topnav-page-selection"></ul></div></div><div class=topnav-page-selection><a id=active href=https://iceberg.apache.org/docs/fd-update-latestt/../../docs/latest>Docs</a></div><div class=topnav-page-selection><a href=https://iceberg.apache.org/docs/fd-update-latestt/../../releases>Releases</a></div class="topnav-page-selection"><div class=topnav-page-selection><a href=https://iceberg.apache.org/docs/fd-update-latestt/../../roadmap>Roadmap</a></div class="topnav-page-selection"><div class=topnav-page-selection><a href=https://iceberg.apache.org/docs/fd-update-latestt/../../blogs>Blogs</a></div class="topnav-page-selection"><div class=topnav-page-selection><a href=https://iceberg.apache.org/docs/fd-update-latestt/../../talks>Talks</a></div class="topnav-page-selection"><div class=versions-dropdown><div class=topnav-page-selection><a href>Project</a> <i class="fa fa-chevron-down"></i></div class="topnav-page-selection"><div class=versions-dropdown-content><ul><li class=topnav-page-selection><a href=https://iceberg.apache.org/docs/fd-update-latestt/../../community>Community</a></li class="topnav-page-selection"><li class=topnav-page-selection><a href=https://iceberg.apache.org/docs/fd-update-latestt/../../spec>Spec</a></li class="topnav-page-selection"><li class=topnav-page-selection><a href=https://iceberg.apache.org/docs/fd-update-latestt/../../view-spec>View Spec</a></li class="topnav-page-selection"><li class=topnav-page-selection><a href=https://iceberg.apache.org/docs/fd-update-latestt/../../puffin-spec>Puffin Spec</a></li class="topnav-page-selection"><li class=topnav-page-selection><a href=https://iceberg.apache.org/docs/fd-update-latestt/../../multi-engine-support>Multi-Engine Support</a></li class="topnav-page-selection"><li class=topnav-page-selection><a href=https://iceberg.apache.org/docs/fd-update-latestt/../../how-to-release>How To Release</a></li class="topnav-page-selection"><li class=topnav-page-selection><a href=https://iceberg.apache.org/docs/fd-update-latestt/../../terms>Terms</a></li class="topnav-page-selection"></ul></div></div><div class=versions-dropdown><div class=topnav-page-selection><a href>Concepts</a> <i class="fa fa-chevron-down"></i></div class="topnav-page-selection"><div class=versions-dropdown-content><ul><li class=topnav-page-selection><a href=https://iceberg.apache.org/docs/fd-update-latestt/../../catalog>Catalogs</a></li class="topnav-page-selection"></ul></div></div><div class=versions-dropdown><div class=topnav-page-selection><a href>ASF</a> <i class="fa fa-chevron-down"></i></div class="topnav-page-selection"><div class=versions-dropdown-content><ul><li class=topnav-page-selection><a target=_blank href=https://www.apache.org/foundation/sponsorship.html>Donate</a></li class="topnav-page-selection"><li class=topnav-page-selection><a target=_blank href=https://www.apache.org/events/current-event.html>Events</a></li class="topnav-page-selection"><li class=topnav-page-selection><a target=_blank href=https://www.apache.org/licenses/>License</a></li class="topnav-page-selection"><li class=topnav-page-selection><a target=_blank href=https://www.apache.org/security/>Security</a></li class="topnav-page-selection"><li class=topnav-page-selection><a target=_blank href=https://www.apache.org/foundation/thanks.html>Sponsors</a></li class="topnav-page-selection"></ul></div></div><div class=topnav-page-selection><a href=https://github.com/apache/iceberg target=_blank><img src=https://iceberg.apache.org/docs/fd-update-latestt//img/GitHub-Mark.png target=_blank class=top-navbar-logo></a></div><div class=topnav-page-selection><a href=https://join.slack.com/t/apache-iceberg/shared_invite/zt-287g3akar-K9Oe_En5j1UL7Y_Ikpai3A target=_blank><img src=https://iceberg.apache.org/docs/fd-update-latestt//img/Slack_Mark_Web.png target=_blank class=top-navbar-logo></a></div></div></topsection></nav><section><div id=search-results-container><ul id=search-results></ul></div></section><body dir=ltr><section><div class="grid-container leftnav-and-toc"><div class="sidebar markdown-body"><div id=full><ul><li><a href=../><span>Introduction</span></a></li><li><a class="chevron-toggle collapsed" data-toggle=collapse data-parent=full href=#Tables><span>Tables</span>
<i class="fa fa-chevron-right"></i>
<i class="fa fa-chevron-down"></i></a></li><div id=Tables class=collapse><ul class=sub-menu><li><a href=../branching/>Branching and Tagging</a></li><li><a href=../configuration/>Configuration</a></li><li><a href=../evolution/>Evolution</a></li><li><a href=../maintenance/>Maintenance</a></li><li><a href=../metrics-reporting/>Metrics Reporting</a></li><li><a href=../partitioning/>Partitioning</a></li><li><a href=../performance/>Performance</a></li><li><a href=../reliability/>Reliability</a></li><li><a href=../schemas/>Schemas</a></li></ul></div><li><a class="chevron-toggle collapsed" data-toggle=collapse data-parent=full href=#Spark><span>Spark</span>
<i class="fa fa-chevron-right"></i>
<i class="fa fa-chevron-down"></i></a></li><div id=Spark class=collapse><ul class=sub-menu><li><a href=../getting-started/>Getting Started</a></li><li><a href=../spark-configuration/>Configuration</a></li><li><a href=../spark-ddl/>DDL</a></li><li><a href=../spark-procedures/>Procedures</a></li><li><a href=../spark-queries/>Queries</a></li><li><a href=../spark-structured-streaming/>Structured Streaming</a></li><li><a href=../spark-writes/>Writes</a></li></ul></div><li><a class=chevron-toggle data-toggle=collapse data-parent=full href=#Flink><span>Flink</span>
<i class="fa fa-chevron-right"></i>
<i class="fa fa-chevron-down"></i></a></li><div id=Flink class="collapse in"><ul class=sub-menu><li><a href=../flink/>Flink Getting Started</a></li><li><a href=../flink-connector/>Flink Connector</a></li><li><a href=../flink-ddl/>Flink DDL</a></li><li><a id=active href=../flink-queries/>Flink Queries</a></li><li><a href=../flink-writes/>Flink Writes</a></li><li><a href=../flink-actions/>Flink Actions</a></li><li><a href=../flink-configuration/>Flink Configuration</a></li></ul></div><li><a href=../hive/><span>Hive</span></a></li><li><a target=_blank href=https://trino.io/docs/current/connector/iceberg.html><span>Trino</span></a></li><li><a target=_blank href=https://clickhouse.com/docs/en/engines/table-engines/integrations/iceberg><span>ClickHouse</span></a></li><li><a target=_blank href=https://prestodb.io/docs/current/connector/iceberg.html><span>Presto</span></a></li><li><a target=_blank href=https://docs.dremio.com/data-formats/apache-iceberg/><span>Dremio</span></a></li><li><a target=_blank href=https://docs.starrocks.io/en-us/latest/data_source/catalog/iceberg_catalog><span>StarRocks</span></a></li><li><a target=_blank href=https://docs.aws.amazon.com/athena/latest/ug/querying-iceberg.html><span>Amazon Athena</span></a></li><li><a target=_blank href=https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-iceberg-use-cluster.html><span>Amazon EMR</span></a></li><li><a target=_blank href=https://impala.apache.org/docs/build/html/topics/impala_iceberg.html><span>Impala</span></a></li><li><a target=_blank href=https://doris.apache.org/docs/dev/lakehouse/multi-catalog/iceberg><span>Doris</span></a></li><li><a class="chevron-toggle collapsed" data-toggle=collapse data-parent=full href=#Integrations><span>Integrations</span>
<i class="fa fa-chevron-right"></i>
<i class="fa fa-chevron-down"></i></a></li><div id=Integrations class=collapse><ul class=sub-menu><li><a href=../aws/>AWS</a></li><li><a href=../dell/>Dell</a></li><li><a href=../jdbc/>JDBC</a></li><li><a href=../nessie/>Nessie</a></li></ul></div><li><a class="chevron-toggle collapsed" data-toggle=collapse data-parent=full href=#API><span>API</span>
<i class="fa fa-chevron-right"></i>
<i class="fa fa-chevron-down"></i></a></li><div id=API class=collapse><ul class=sub-menu><li><a href=../java-api-quickstart/>Java Quickstart</a></li><li><a href=../api/>Java API</a></li><li><a href=../custom-catalog/>Java Custom Catalog</a></li></ul></div><li><a class="chevron-toggle collapsed" data-toggle=collapse data-parent=full href=#Migration><span>Migration</span>
<i class="fa fa-chevron-right"></i>
<i class="fa fa-chevron-down"></i></a></li><div id=Migration class=collapse><ul class=sub-menu><li><a href=../table-migration/>Overview</a></li><li><a href=../hive-migration/>Hive Migration</a></li><li><a href=../delta-lake-migration/>Delta Lake Migration</a></li></ul></div><li><a href=https://iceberg.apache.org/docs/fd-update-latestt/../../javadoc/latest><span>Javadoc</span></a></li><li><a target=_blank href=https://py.iceberg.apache.org/><span>PyIceberg</span></a></li></div></div><div id=content class=markdown-body><div class=margin-for-toc><h1 id=flink-queries>Flink Queries</h1><p>Iceberg support streaming and batch read With <a href=https://flink.apache.org/>Apache Flink</a>&rsquo;s DataStream API and Table API.</p><h2 id=reading-with-sql>Reading with SQL</h2><p>Iceberg support both streaming and batch read in Flink. Execute the following sql command to switch execution mode from <code>streaming</code> to <code>batch</code>, and vice versa:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=display:flex><span><span style=color:#75715e>-- Execute the flink job in streaming mode for current session context
</span></span></span><span style=display:flex><span><span style=color:#75715e></span><span style=color:#66d9ef>SET</span> execution.runtime<span style=color:#f92672>-</span><span style=color:#66d9ef>mode</span> <span style=color:#f92672>=</span> streaming;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>-- Execute the flink job in batch mode for current session context
</span></span></span><span style=display:flex><span><span style=color:#75715e></span><span style=color:#66d9ef>SET</span> execution.runtime<span style=color:#f92672>-</span><span style=color:#66d9ef>mode</span> <span style=color:#f92672>=</span> batch;
</span></span></code></pre></div><h3 id=flink-batch-read>Flink batch read</h3><p>Submit a Flink <strong>batch</strong> job using the following sentences:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=display:flex><span><span style=color:#75715e>-- Execute the flink job in batch mode for current session context
</span></span></span><span style=display:flex><span><span style=color:#75715e></span><span style=color:#66d9ef>SET</span> execution.runtime<span style=color:#f92672>-</span><span style=color:#66d9ef>mode</span> <span style=color:#f92672>=</span> batch;
</span></span><span style=display:flex><span><span style=color:#66d9ef>SELECT</span> <span style=color:#f92672>*</span> <span style=color:#66d9ef>FROM</span> sample;
</span></span></code></pre></div><h3 id=flink-streaming-read>Flink streaming read</h3><p>Iceberg supports processing incremental data in Flink streaming jobs which starts from a historical snapshot-id:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=display:flex><span><span style=color:#75715e>-- Submit the flink job in streaming mode for current session.
</span></span></span><span style=display:flex><span><span style=color:#75715e></span><span style=color:#66d9ef>SET</span> execution.runtime<span style=color:#f92672>-</span><span style=color:#66d9ef>mode</span> <span style=color:#f92672>=</span> streaming;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>-- Enable this switch because streaming read SQL will provide few job options in flink SQL hint options.
</span></span></span><span style=display:flex><span><span style=color:#75715e></span><span style=color:#66d9ef>SET</span> <span style=color:#66d9ef>table</span>.<span style=color:#66d9ef>dynamic</span><span style=color:#f92672>-</span><span style=color:#66d9ef>table</span><span style=color:#f92672>-</span><span style=color:#66d9ef>options</span>.enabled<span style=color:#f92672>=</span><span style=color:#66d9ef>true</span>;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>-- Read all the records from the iceberg current snapshot, and then read incremental data starting from that snapshot.
</span></span></span><span style=display:flex><span><span style=color:#75715e></span><span style=color:#66d9ef>SELECT</span> <span style=color:#f92672>*</span> <span style=color:#66d9ef>FROM</span> sample <span style=color:#75715e>/*+ OPTIONS(&#39;streaming&#39;=&#39;true&#39;, &#39;monitor-interval&#39;=&#39;1s&#39;)*/</span> ;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>-- Read all incremental data starting from the snapshot-id &#39;3821550127947089987&#39; (records from this snapshot will be excluded).
</span></span></span><span style=display:flex><span><span style=color:#75715e></span><span style=color:#66d9ef>SELECT</span> <span style=color:#f92672>*</span> <span style=color:#66d9ef>FROM</span> sample <span style=color:#75715e>/*+ OPTIONS(&#39;streaming&#39;=&#39;true&#39;, &#39;monitor-interval&#39;=&#39;1s&#39;, &#39;start-snapshot-id&#39;=&#39;3821550127947089987&#39;)*/</span> ;
</span></span></code></pre></div><p>There are some options that could be set in Flink SQL hint options for streaming job, see <a href=#Read-options>read options</a> for details.</p><h3 id=flip-27-source-for-sql>FLIP-27 source for SQL</h3><p>Here are the SQL settings for the <a href=https://cwiki.apache.org/confluence/display/FLINK/FLIP-27%3A+Refactor+Source+Interface>FLIP-27</a> source. All other SQL settings and options documented above are applicable to the FLIP-27 source.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=display:flex><span><span style=color:#75715e>-- Opt in the FLIP-27 source. Default is false.
</span></span></span><span style=display:flex><span><span style=color:#75715e></span><span style=color:#66d9ef>SET</span> <span style=color:#66d9ef>table</span>.<span style=color:#66d9ef>exec</span>.iceberg.use<span style=color:#f92672>-</span>flip27<span style=color:#f92672>-</span><span style=color:#66d9ef>source</span> <span style=color:#f92672>=</span> <span style=color:#66d9ef>true</span>;
</span></span></code></pre></div><h3 id=reading-branches-and-tags-with-sql>Reading branches and tags with SQL</h3><p>Branch and tags can be read via SQL by specifying options. For more details
refer to <a href=../flink-configuration/#read-options>Flink Configuration</a></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=display:flex><span><span style=color:#75715e>--- Read from branch b1
</span></span></span><span style=display:flex><span><span style=color:#75715e></span><span style=color:#66d9ef>SELECT</span> <span style=color:#f92672>*</span> <span style=color:#66d9ef>FROM</span> <span style=color:#66d9ef>table</span> <span style=color:#75715e>/*+ OPTIONS(&#39;branch&#39;=&#39;b1&#39;) */</span> ;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>--- Read from tag t1
</span></span></span><span style=display:flex><span><span style=color:#75715e></span><span style=color:#66d9ef>SELECT</span> <span style=color:#f92672>*</span> <span style=color:#66d9ef>FROM</span> <span style=color:#66d9ef>table</span> <span style=color:#75715e>/*+ OPTIONS(&#39;tag&#39;=&#39;t1&#39;) */</span>;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>--- Incremental scan from tag t1 to tag t2
</span></span></span><span style=display:flex><span><span style=color:#75715e></span><span style=color:#66d9ef>SELECT</span> <span style=color:#f92672>*</span> <span style=color:#66d9ef>FROM</span> <span style=color:#66d9ef>table</span> <span style=color:#75715e>/*+ OPTIONS(&#39;streaming&#39;=&#39;true&#39;, &#39;monitor-interval&#39;=&#39;1s&#39;, &#39;start-tag&#39;=&#39;t1&#39;, &#39;end-tag&#39;=&#39;t2&#39;) */</span>;
</span></span></code></pre></div><h2 id=reading-with-datastream>Reading with DataStream</h2><p>Iceberg support streaming or batch read in Java API now.</p><h3 id=batch-read>Batch Read</h3><p>This example will read all records from iceberg table and then print to the stdout console in flink batch job:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-java data-lang=java><span style=display:flex><span>StreamExecutionEnvironment env <span style=color:#f92672>=</span> StreamExecutionEnvironment.<span style=color:#a6e22e>createLocalEnvironment</span>();
</span></span><span style=display:flex><span>TableLoader tableLoader <span style=color:#f92672>=</span> TableLoader.<span style=color:#a6e22e>fromHadoopTable</span>(<span style=color:#e6db74>&#34;hdfs://nn:8020/warehouse/path&#34;</span>);
</span></span><span style=display:flex><span>DataStream<span style=color:#f92672>&lt;</span>RowData<span style=color:#f92672>&gt;</span> batch <span style=color:#f92672>=</span> FlinkSource.<span style=color:#a6e22e>forRowData</span>()
</span></span><span style=display:flex><span>     .<span style=color:#a6e22e>env</span>(env)
</span></span><span style=display:flex><span>     .<span style=color:#a6e22e>tableLoader</span>(tableLoader)
</span></span><span style=display:flex><span>     .<span style=color:#a6e22e>streaming</span>(<span style=color:#66d9ef>false</span>)
</span></span><span style=display:flex><span>     .<span style=color:#a6e22e>build</span>();
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>// Print all records to stdout.</span>
</span></span><span style=display:flex><span>batch.<span style=color:#a6e22e>print</span>();
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>// Submit and execute this batch read job.</span>
</span></span><span style=display:flex><span>env.<span style=color:#a6e22e>execute</span>(<span style=color:#e6db74>&#34;Test Iceberg Batch Read&#34;</span>);
</span></span></code></pre></div><h3 id=streaming-read>Streaming read</h3><p>This example will read incremental records which start from snapshot-id &lsquo;3821550127947089987&rsquo; and print to stdout console in flink streaming job:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-java data-lang=java><span style=display:flex><span>StreamExecutionEnvironment env <span style=color:#f92672>=</span> StreamExecutionEnvironment.<span style=color:#a6e22e>createLocalEnvironment</span>();
</span></span><span style=display:flex><span>TableLoader tableLoader <span style=color:#f92672>=</span> TableLoader.<span style=color:#a6e22e>fromHadoopTable</span>(<span style=color:#e6db74>&#34;hdfs://nn:8020/warehouse/path&#34;</span>);
</span></span><span style=display:flex><span>DataStream<span style=color:#f92672>&lt;</span>RowData<span style=color:#f92672>&gt;</span> stream <span style=color:#f92672>=</span> FlinkSource.<span style=color:#a6e22e>forRowData</span>()
</span></span><span style=display:flex><span>     .<span style=color:#a6e22e>env</span>(env)
</span></span><span style=display:flex><span>     .<span style=color:#a6e22e>tableLoader</span>(tableLoader)
</span></span><span style=display:flex><span>     .<span style=color:#a6e22e>streaming</span>(<span style=color:#66d9ef>true</span>)
</span></span><span style=display:flex><span>     .<span style=color:#a6e22e>startSnapshotId</span>(3821550127947089987L)
</span></span><span style=display:flex><span>     .<span style=color:#a6e22e>build</span>();
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>// Print all records to stdout.</span>
</span></span><span style=display:flex><span>stream.<span style=color:#a6e22e>print</span>();
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>// Submit and execute this streaming read job.</span>
</span></span><span style=display:flex><span>env.<span style=color:#a6e22e>execute</span>(<span style=color:#e6db74>&#34;Test Iceberg Streaming Read&#34;</span>);
</span></span></code></pre></div><p>There are other options that can be set, please see the <a href=../../../javadoc/1.4.2/org/apache/iceberg/flink/source/FlinkSource.html>FlinkSource#Builder</a>.</p><h2 id=reading-with-datastream-flip-27-source>Reading with DataStream (FLIP-27 source)</h2><p><a href=https://cwiki.apache.org/confluence/display/FLINK/FLIP-27%3A+Refactor+Source+Interface>FLIP-27 source interface</a>
was introduced in Flink 1.12. It aims to solve several shortcomings of the old <code>SourceFunction</code>
streaming source interface. It also unifies the source interfaces for both batch and streaming executions.
Most source connectors (like Kafka, file) in Flink repo have migrated to the FLIP-27 interface.
Flink is planning to deprecate the old <code>SourceFunction</code> interface in the near future.</p><p>A FLIP-27 based Flink <code>IcebergSource</code> is added in <code>iceberg-flink</code> module. The FLIP-27 <code>IcebergSource</code> is currently an experimental feature.</p><h3 id=batch-read-1>Batch Read</h3><p>This example will read all records from iceberg table and then print to the stdout console in flink batch job:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-java data-lang=java><span style=display:flex><span>StreamExecutionEnvironment env <span style=color:#f92672>=</span> StreamExecutionEnvironment.<span style=color:#a6e22e>createLocalEnvironment</span>();
</span></span><span style=display:flex><span>TableLoader tableLoader <span style=color:#f92672>=</span> TableLoader.<span style=color:#a6e22e>fromHadoopTable</span>(<span style=color:#e6db74>&#34;hdfs://nn:8020/warehouse/path&#34;</span>);
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>IcebergSource<span style=color:#f92672>&lt;</span>RowData<span style=color:#f92672>&gt;</span> source <span style=color:#f92672>=</span> IcebergSource.<span style=color:#a6e22e>forRowData</span>()
</span></span><span style=display:flex><span>    .<span style=color:#a6e22e>tableLoader</span>(tableLoader)
</span></span><span style=display:flex><span>    .<span style=color:#a6e22e>assignerFactory</span>(<span style=color:#66d9ef>new</span> SimpleSplitAssignerFactory())
</span></span><span style=display:flex><span>    .<span style=color:#a6e22e>build</span>();
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>DataStream<span style=color:#f92672>&lt;</span>RowData<span style=color:#f92672>&gt;</span> batch <span style=color:#f92672>=</span> env.<span style=color:#a6e22e>fromSource</span>(
</span></span><span style=display:flex><span>    source,
</span></span><span style=display:flex><span>    WatermarkStrategy.<span style=color:#a6e22e>noWatermarks</span>(),
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;My Iceberg Source&#34;</span>,
</span></span><span style=display:flex><span>    TypeInformation.<span style=color:#a6e22e>of</span>(RowData.<span style=color:#a6e22e>class</span>));
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>// Print all records to stdout.</span>
</span></span><span style=display:flex><span>batch.<span style=color:#a6e22e>print</span>();
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>// Submit and execute this batch read job.</span>
</span></span><span style=display:flex><span>env.<span style=color:#a6e22e>execute</span>(<span style=color:#e6db74>&#34;Test Iceberg Batch Read&#34;</span>);
</span></span></code></pre></div><h3 id=streaming-read-1>Streaming read</h3><p>This example will start the streaming read from the latest table snapshot (inclusive).
Every 60s, it polls Iceberg table to discover new append-only snapshots.
CDC read is not supported yet.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-java data-lang=java><span style=display:flex><span>StreamExecutionEnvironment env <span style=color:#f92672>=</span> StreamExecutionEnvironment.<span style=color:#a6e22e>createLocalEnvironment</span>();
</span></span><span style=display:flex><span>TableLoader tableLoader <span style=color:#f92672>=</span> TableLoader.<span style=color:#a6e22e>fromHadoopTable</span>(<span style=color:#e6db74>&#34;hdfs://nn:8020/warehouse/path&#34;</span>);
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>IcebergSource source <span style=color:#f92672>=</span> IcebergSource.<span style=color:#a6e22e>forRowData</span>()
</span></span><span style=display:flex><span>    .<span style=color:#a6e22e>tableLoader</span>(tableLoader)
</span></span><span style=display:flex><span>    .<span style=color:#a6e22e>assignerFactory</span>(<span style=color:#66d9ef>new</span> SimpleSplitAssignerFactory())
</span></span><span style=display:flex><span>    .<span style=color:#a6e22e>streaming</span>(<span style=color:#66d9ef>true</span>)
</span></span><span style=display:flex><span>    .<span style=color:#a6e22e>streamingStartingStrategy</span>(StreamingStartingStrategy.<span style=color:#a6e22e>INCREMENTAL_FROM_LATEST_SNAPSHOT</span>)
</span></span><span style=display:flex><span>    .<span style=color:#a6e22e>monitorInterval</span>(Duration.<span style=color:#a6e22e>ofSeconds</span>(60))
</span></span><span style=display:flex><span>    .<span style=color:#a6e22e>build</span>();
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>DataStream<span style=color:#f92672>&lt;</span>RowData<span style=color:#f92672>&gt;</span> stream <span style=color:#f92672>=</span> env.<span style=color:#a6e22e>fromSource</span>(
</span></span><span style=display:flex><span>    source,
</span></span><span style=display:flex><span>    WatermarkStrategy.<span style=color:#a6e22e>noWatermarks</span>(),
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;My Iceberg Source&#34;</span>,
</span></span><span style=display:flex><span>    TypeInformation.<span style=color:#a6e22e>of</span>(RowData.<span style=color:#a6e22e>class</span>));
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>// Print all records to stdout.</span>
</span></span><span style=display:flex><span>stream.<span style=color:#a6e22e>print</span>();
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>// Submit and execute this streaming read job.</span>
</span></span><span style=display:flex><span>env.<span style=color:#a6e22e>execute</span>(<span style=color:#e6db74>&#34;Test Iceberg Streaming Read&#34;</span>);
</span></span></code></pre></div><p>There are other options that could be set by Java API, please see the
<a href=../../../javadoc/1.4.2/org/apache/iceberg/flink/source/IcebergSource.html>IcebergSource#Builder</a>.</p><h3 id=reading-branches-and-tags-with-datastream>Reading branches and tags with DataStream</h3><p>Branches and tags can also be read via the DataStream API</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-java data-lang=java><span style=display:flex><span>StreamExecutionEnvironment env <span style=color:#f92672>=</span> StreamExecutionEnvironment.<span style=color:#a6e22e>createLocalEnvironment</span>();
</span></span><span style=display:flex><span>TableLoader tableLoader <span style=color:#f92672>=</span> TableLoader.<span style=color:#a6e22e>fromHadoopTable</span>(<span style=color:#e6db74>&#34;hdfs://nn:8020/warehouse/path&#34;</span>);
</span></span><span style=display:flex><span><span style=color:#75715e>// Read from branch</span>
</span></span><span style=display:flex><span>DataStream<span style=color:#f92672>&lt;</span>RowData<span style=color:#f92672>&gt;</span> batch <span style=color:#f92672>=</span> FlinkSource.<span style=color:#a6e22e>forRowData</span>()
</span></span><span style=display:flex><span>    .<span style=color:#a6e22e>env</span>(env)
</span></span><span style=display:flex><span>    .<span style=color:#a6e22e>tableLoader</span>(tableLoader)
</span></span><span style=display:flex><span>    .<span style=color:#a6e22e>branch</span>(<span style=color:#e6db74>&#34;test-branch&#34;</span>)
</span></span><span style=display:flex><span>    .<span style=color:#a6e22e>streaming</span>(<span style=color:#66d9ef>false</span>)
</span></span><span style=display:flex><span>    .<span style=color:#a6e22e>build</span>();
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>// Read from tag</span>
</span></span><span style=display:flex><span>DataStream<span style=color:#f92672>&lt;</span>RowData<span style=color:#f92672>&gt;</span> batch <span style=color:#f92672>=</span> FlinkSource.<span style=color:#a6e22e>forRowData</span>()
</span></span><span style=display:flex><span>    .<span style=color:#a6e22e>env</span>(env)
</span></span><span style=display:flex><span>    .<span style=color:#a6e22e>tableLoader</span>(tableLoader)
</span></span><span style=display:flex><span>    .<span style=color:#a6e22e>tag</span>(<span style=color:#e6db74>&#34;test-tag&#34;</span>)
</span></span><span style=display:flex><span>    .<span style=color:#a6e22e>streaming</span>(<span style=color:#66d9ef>false</span>)
</span></span><span style=display:flex><span>    .<span style=color:#a6e22e>build</span>();
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>// Streaming read from start-tag</span>
</span></span><span style=display:flex><span>DataStream<span style=color:#f92672>&lt;</span>RowData<span style=color:#f92672>&gt;</span> batch <span style=color:#f92672>=</span> FlinkSource.<span style=color:#a6e22e>forRowData</span>()
</span></span><span style=display:flex><span>    .<span style=color:#a6e22e>env</span>(env)
</span></span><span style=display:flex><span>    .<span style=color:#a6e22e>tableLoader</span>(tableLoader)
</span></span><span style=display:flex><span>    .<span style=color:#a6e22e>streaming</span>(<span style=color:#66d9ef>true</span>)
</span></span><span style=display:flex><span>    .<span style=color:#a6e22e>startTag</span>(<span style=color:#e6db74>&#34;test-tag&#34;</span>)
</span></span><span style=display:flex><span>    .<span style=color:#a6e22e>build</span>();
</span></span></code></pre></div><h3 id=read-as-avro-genericrecord>Read as Avro GenericRecord</h3><p>FLIP-27 Iceberg source provides <code>AvroGenericRecordReaderFunction</code> that converts
Flink <code>RowData</code> Avro <code>GenericRecord</code>. You can use the convert to read from
Iceberg table as Avro GenericRecord DataStream.</p><p>Please make sure <code>flink-avro</code> jar is included in the classpath.
Also <code>iceberg-flink-runtime</code> shaded bundle jar can&rsquo;t be used
because the runtime jar shades the avro package.
Please use non-shaded <code>iceberg-flink</code> jar instead.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-java data-lang=java><span style=display:flex><span>TableLoader tableLoader <span style=color:#f92672>=</span> ...;
</span></span><span style=display:flex><span>Table table;
</span></span><span style=display:flex><span><span style=color:#66d9ef>try</span> (TableLoader loader <span style=color:#f92672>=</span> tableLoader) {
</span></span><span style=display:flex><span>    loader.<span style=color:#a6e22e>open</span>();
</span></span><span style=display:flex><span>    table <span style=color:#f92672>=</span> loader.<span style=color:#a6e22e>loadTable</span>();
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>AvroGenericRecordReaderFunction readerFunction <span style=color:#f92672>=</span> AvroGenericRecordReaderFunction.<span style=color:#a6e22e>fromTable</span>(table);
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>IcebergSource<span style=color:#f92672>&lt;</span>GenericRecord<span style=color:#f92672>&gt;</span> source <span style=color:#f92672>=</span>
</span></span><span style=display:flex><span>    IcebergSource.<span style=color:#f92672>&lt;</span>GenericRecord<span style=color:#f92672>&gt;</span>builder()
</span></span><span style=display:flex><span>        .<span style=color:#a6e22e>tableLoader</span>(tableLoader)
</span></span><span style=display:flex><span>        .<span style=color:#a6e22e>readerFunction</span>(readerFunction)
</span></span><span style=display:flex><span>        .<span style=color:#a6e22e>assignerFactory</span>(<span style=color:#66d9ef>new</span> SimpleSplitAssignerFactory())
</span></span><span style=display:flex><span>        ...
</span></span><span style=display:flex><span>        .<span style=color:#a6e22e>build</span>();
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>DataStream<span style=color:#f92672>&lt;</span>Row<span style=color:#f92672>&gt;</span> stream <span style=color:#f92672>=</span> env.<span style=color:#a6e22e>fromSource</span>(source, WatermarkStrategy.<span style=color:#a6e22e>noWatermarks</span>(),
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;Iceberg Source as Avro GenericRecord&#34;</span>, <span style=color:#66d9ef>new</span> GenericRecordAvroTypeInfo(avroSchema));
</span></span></code></pre></div><h2 id=options>Options</h2><h3 id=read-options>Read options</h3><p>Flink read options are passed when configuring the Flink IcebergSource:</p><pre tabindex=0><code>IcebergSource.forRowData()
    .tableLoader(TableLoader.fromCatalog(...))
    .assignerFactory(new SimpleSplitAssignerFactory())
    .streaming(true)
    .streamingStartingStrategy(StreamingStartingStrategy.INCREMENTAL_FROM_LATEST_SNAPSHOT)
    .startSnapshotId(3821550127947089987L)
    .monitorInterval(Duration.ofMillis(10L)) // or .set(&#34;monitor-interval&#34;, &#34;10s&#34;) \ set(FlinkReadOptions.MONITOR_INTERVAL, &#34;10s&#34;)
    .build()
</code></pre><p>For Flink SQL, read options can be passed in via SQL hints like this:</p><pre tabindex=0><code>SELECT * FROM tableName /*+ OPTIONS(&#39;monitor-interval&#39;=&#39;10s&#39;) */
...
</code></pre><p>Options can be passed in via Flink configuration, which will be applied to current session. Note that not all options support this mode.</p><pre tabindex=0><code>env.getConfig()
    .getConfiguration()
    .set(FlinkReadOptions.SPLIT_FILE_OPEN_COST_OPTION, 1000L);
...
</code></pre><p>Check out all the options here: <a href=../flink-configuration#read-options>read-options</a></p><h2 id=inspecting-tables>Inspecting tables</h2><p>To inspect a table&rsquo;s history, snapshots, and other metadata, Iceberg supports metadata tables.</p><p>Metadata tables are identified by adding the metadata table name after the original table name. For example, history for <code>db.table</code> is read using <code>db.table$history</code>.</p><h3 id=history>History</h3><p>To show table history:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=display:flex><span><span style=color:#66d9ef>SELECT</span> <span style=color:#f92672>*</span> <span style=color:#66d9ef>FROM</span> prod.db.<span style=color:#66d9ef>table</span><span style=color:#960050;background-color:#1e0010>$</span>history;
</span></span></code></pre></div><table><thead><tr><th>made_current_at</th><th>snapshot_id</th><th>parent_id</th><th>is_current_ancestor</th></tr></thead><tbody><tr><td>2019-02-08 03:29:51.215</td><td>5781947118336215154</td><td>NULL</td><td>true</td></tr><tr><td>2019-02-08 03:47:55.948</td><td>5179299526185056830</td><td>5781947118336215154</td><td>true</td></tr><tr><td>2019-02-09 16:24:30.13</td><td>296410040247533544</td><td>5179299526185056830</td><td>false</td></tr><tr><td>2019-02-09 16:32:47.336</td><td>2999875608062437330</td><td>5179299526185056830</td><td>true</td></tr><tr><td>2019-02-09 19:42:03.919</td><td>8924558786060583479</td><td>2999875608062437330</td><td>true</td></tr><tr><td>2019-02-09 19:49:16.343</td><td>6536733823181975045</td><td>8924558786060583479</td><td>true</td></tr></tbody></table><div class=info><strong>This shows a commit that was rolled back.</strong> In this example, snapshot 296410040247533544 and 2999875608062437330 have the same parent snapshot 5179299526185056830. Snapshot 296410040247533544 was rolled back and is <em>not</em> an ancestor of the current table state.</div><h3 id=metadata-log-entries>Metadata Log Entries</h3><p>To show table metadata log entries:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=display:flex><span><span style=color:#66d9ef>SELECT</span> <span style=color:#f92672>*</span> <span style=color:#66d9ef>from</span> prod.db.<span style=color:#66d9ef>table</span><span style=color:#960050;background-color:#1e0010>$</span>metadata_log_entries;
</span></span></code></pre></div><table><thead><tr><th>timestamp</th><th>file</th><th>latest_snapshot_id</th><th>latest_schema_id</th><th>latest_sequence_number</th></tr></thead><tbody><tr><td>2022-07-28 10:43:52.93</td><td>s3://&mldr;/table/metadata/00000-9441e604-b3c2-498a-a45a-6320e8ab9006.metadata.json</td><td>null</td><td>null</td><td>null</td></tr><tr><td>2022-07-28 10:43:57.487</td><td>s3://&mldr;/table/metadata/00001-f30823df-b745-4a0a-b293-7532e0c99986.metadata.json</td><td>170260833677645300</td><td>0</td><td>1</td></tr><tr><td>2022-07-28 10:43:58.25</td><td>s3://&mldr;/table/metadata/00002-2cc2837a-02dc-4687-acc1-b4d86ea486f4.metadata.json</td><td>958906493976709774</td><td>0</td><td>2</td></tr></tbody></table><h3 id=snapshots>Snapshots</h3><p>To show the valid snapshots for a table:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=display:flex><span><span style=color:#66d9ef>SELECT</span> <span style=color:#f92672>*</span> <span style=color:#66d9ef>FROM</span> prod.db.<span style=color:#66d9ef>table</span><span style=color:#960050;background-color:#1e0010>$</span>snapshots;
</span></span></code></pre></div><table><thead><tr><th>committed_at</th><th>snapshot_id</th><th>parent_id</th><th>operation</th><th>manifest_list</th><th>summary</th></tr></thead><tbody><tr><td>2019-02-08 03:29:51.215</td><td>57897183625154</td><td>null</td><td>append</td><td>s3://&mldr;/table/metadata/snap-57897183625154-1.avro</td><td>{ added-records -> 2478404, total-records -> 2478404, added-data-files -> 438, total-data-files -> 438, flink.job-id -> 2e274eecb503d85369fb390e8956c813 }</td></tr></tbody></table><p>You can also join snapshots to table history. For example, this query will show table history, with the application ID that wrote each snapshot:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=display:flex><span><span style=color:#66d9ef>select</span>
</span></span><span style=display:flex><span>    h.made_current_at,
</span></span><span style=display:flex><span>    s.<span style=color:#66d9ef>operation</span>,
</span></span><span style=display:flex><span>    h.snapshot_id,
</span></span><span style=display:flex><span>    h.is_current_ancestor,
</span></span><span style=display:flex><span>    s.summary[<span style=color:#e6db74>&#39;flink.job-id&#39;</span>]
</span></span><span style=display:flex><span><span style=color:#66d9ef>from</span> prod.db.<span style=color:#66d9ef>table</span><span style=color:#960050;background-color:#1e0010>$</span>history h
</span></span><span style=display:flex><span><span style=color:#66d9ef>join</span> prod.db.<span style=color:#66d9ef>table</span><span style=color:#960050;background-color:#1e0010>$</span>snapshots s
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>on</span> h.snapshot_id <span style=color:#f92672>=</span> s.snapshot_id
</span></span><span style=display:flex><span><span style=color:#66d9ef>order</span> <span style=color:#66d9ef>by</span> made_current_at
</span></span></code></pre></div><table><thead><tr><th>made_current_at</th><th>operation</th><th>snapshot_id</th><th>is_current_ancestor</th><th>summary[flink.job-id]</th></tr></thead><tbody><tr><td>2019-02-08 03:29:51.215</td><td>append</td><td>57897183625154</td><td>true</td><td>2e274eecb503d85369fb390e8956c813</td></tr></tbody></table><h3 id=files>Files</h3><p>To show a table&rsquo;s current data files:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=display:flex><span><span style=color:#66d9ef>SELECT</span> <span style=color:#f92672>*</span> <span style=color:#66d9ef>FROM</span> prod.db.<span style=color:#66d9ef>table</span><span style=color:#960050;background-color:#1e0010>$</span>files;
</span></span></code></pre></div><table><thead><tr><th>content</th><th>file_path</th><th>file_format</th><th>spec_id</th><th>partition</th><th>record_count</th><th>file_size_in_bytes</th><th>column_sizes</th><th>value_counts</th><th>null_value_counts</th><th>nan_value_counts</th><th>lower_bounds</th><th>upper_bounds</th><th>key_metadata</th><th>split_offsets</th><th>equality_ids</th><th>sort_order_id</th></tr></thead><tbody><tr><td>0</td><td>s3:/&mldr;/table/data/00000-3-8d6d60e8-d427-4809-bcf0-f5d45a4aad96.parquet</td><td>PARQUET</td><td>0</td><td>{1999-01-01, 01}</td><td>1</td><td>597</td><td>[1 -> 90, 2 -> 62]</td><td>[1 -> 1, 2 -> 1]</td><td>[1 -> 0, 2 -> 0]</td><td>[]</td><td>[1 -> , 2 -> c]</td><td>[1 -> , 2 -> c]</td><td>null</td><td>[4]</td><td>null</td><td>null</td></tr><tr><td>0</td><td>s3:/&mldr;/table/data/00001-4-8d6d60e8-d427-4809-bcf0-f5d45a4aad96.parquet</td><td>PARQUET</td><td>0</td><td>{1999-01-01, 02}</td><td>1</td><td>597</td><td>[1 -> 90, 2 -> 62]</td><td>[1 -> 1, 2 -> 1]</td><td>[1 -> 0, 2 -> 0]</td><td>[]</td><td>[1 -> , 2 -> b]</td><td>[1 -> , 2 -> b]</td><td>null</td><td>[4]</td><td>null</td><td>null</td></tr><tr><td>0</td><td>s3:/&mldr;/table/data/00002-5-8d6d60e8-d427-4809-bcf0-f5d45a4aad96.parquet</td><td>PARQUET</td><td>0</td><td>{1999-01-01, 03}</td><td>1</td><td>597</td><td>[1 -> 90, 2 -> 62]</td><td>[1 -> 1, 2 -> 1]</td><td>[1 -> 0, 2 -> 0]</td><td>[]</td><td>[1 -> , 2 -> a]</td><td>[1 -> , 2 -> a]</td><td>null</td><td>[4]</td><td>null</td><td>null</td></tr></tbody></table><h3 id=manifests>Manifests</h3><p>To show a table&rsquo;s current file manifests:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=display:flex><span><span style=color:#66d9ef>SELECT</span> <span style=color:#f92672>*</span> <span style=color:#66d9ef>FROM</span> prod.db.<span style=color:#66d9ef>table</span><span style=color:#960050;background-color:#1e0010>$</span>manifests;
</span></span></code></pre></div><table><thead><tr><th>path</th><th>length</th><th>partition_spec_id</th><th>added_snapshot_id</th><th>added_data_files_count</th><th>existing_data_files_count</th><th>deleted_data_files_count</th><th>partition_summaries</th></tr></thead><tbody><tr><td>s3://&mldr;/table/metadata/45b5290b-ee61-4788-b324-b1e2735c0e10-m0.avro</td><td>4479</td><td>0</td><td>6668963634911763636</td><td>8</td><td>0</td><td>0</td><td>[[false,null,2019-05-13,2019-05-15]]</td></tr></tbody></table><p>Note:</p><ol><li>Fields within <code>partition_summaries</code> column of the manifests table correspond to <code>field_summary</code> structs within <a href=../../../spec#manifest-lists>manifest list</a>, with the following order:<ul><li><code>contains_null</code></li><li><code>contains_nan</code></li><li><code>lower_bound</code></li><li><code>upper_bound</code></li></ul></li><li><code>contains_nan</code> could return null, which indicates that this information is not available from the file&rsquo;s metadata.
This usually occurs when reading from V1 table, where <code>contains_nan</code> is not populated.</li></ol><h3 id=partitions>Partitions</h3><p>To show a table&rsquo;s current partitions:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=display:flex><span><span style=color:#66d9ef>SELECT</span> <span style=color:#f92672>*</span> <span style=color:#66d9ef>FROM</span> prod.db.<span style=color:#66d9ef>table</span><span style=color:#960050;background-color:#1e0010>$</span>partitions;
</span></span></code></pre></div><table><thead><tr><th>partition</th><th>spec_id</th><th>record_count</th><th>file_count</th><th>total_data_file_size_in_bytes</th><th>position_delete_record_count</th><th>position_delete_file_count</th><th>equality_delete_record_count</th><th>equality_delete_file_count</th><th>last_updated_at(Î¼s)</th><th>last_updated_snapshot_id</th></tr></thead><tbody><tr><td>{20211001, 11}</td><td>0</td><td>1</td><td>1</td><td>100</td><td>2</td><td>1</td><td>0</td><td>0</td><td>1633086034192000</td><td>9205185327307503337</td></tr><tr><td>{20211002, 11}</td><td>0</td><td>4</td><td>3</td><td>500</td><td>1</td><td>1</td><td>0</td><td>0</td><td>1633172537358000</td><td>867027598972211003</td></tr><tr><td>{20211001, 10}</td><td>0</td><td>7</td><td>4</td><td>700</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1633082598716000</td><td>3280122546965981531</td></tr><tr><td>{20211002, 10}</td><td>0</td><td>3</td><td>2</td><td>400</td><td>0</td><td>0</td><td>1</td><td>1</td><td>1633169159489000</td><td>6941468797545315876</td></tr></tbody></table><p>Note:
For unpartitioned tables, the partitions table will not contain the partition and spec_id fields.</p><h3 id=all-metadata-tables>All Metadata Tables</h3><p>These tables are unions of the metadata tables specific to the current snapshot, and return metadata across all snapshots.</p><div class=danger>The &ldquo;all&rdquo; metadata tables may produce more than one row per data file or manifest file because metadata files may be part of more than one table snapshot.</div><h4 id=all-data-files>All Data Files</h4><p>To show all of the table&rsquo;s data files and each file&rsquo;s metadata:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=display:flex><span><span style=color:#66d9ef>SELECT</span> <span style=color:#f92672>*</span> <span style=color:#66d9ef>FROM</span> prod.db.<span style=color:#66d9ef>table</span><span style=color:#960050;background-color:#1e0010>$</span>all_data_files;
</span></span></code></pre></div><table><thead><tr><th>content</th><th>file_path</th><th>file_format</th><th>partition</th><th>record_count</th><th>file_size_in_bytes</th><th>column_sizes</th><th>value_counts</th><th>null_value_counts</th><th>nan_value_counts</th><th>lower_bounds</th><th>upper_bounds</th><th>key_metadata</th><th>split_offsets</th><th>equality_ids</th><th>sort_order_id</th></tr></thead><tbody><tr><td>0</td><td>s3://&mldr;/dt=20210102/00000-0-756e2512-49ae-45bb-aae3-c0ca475e7879-00001.parquet</td><td>PARQUET</td><td>{20210102}</td><td>14</td><td>2444</td><td>{1 -> 94, 2 -> 17}</td><td>{1 -> 14, 2 -> 14}</td><td>{1 -> 0, 2 -> 0}</td><td>{}</td><td>{1 -> 1, 2 -> 20210102}</td><td>{1 -> 2, 2 -> 20210102}</td><td>null</td><td>[4]</td><td>null</td><td>0</td></tr><tr><td>0</td><td>s3://&mldr;/dt=20210103/00000-0-26222098-032f-472b-8ea5-651a55b21210-00001.parquet</td><td>PARQUET</td><td>{20210103}</td><td>14</td><td>2444</td><td>{1 -> 94, 2 -> 17}</td><td>{1 -> 14, 2 -> 14}</td><td>{1 -> 0, 2 -> 0}</td><td>{}</td><td>{1 -> 1, 2 -> 20210103}</td><td>{1 -> 3, 2 -> 20210103}</td><td>null</td><td>[4]</td><td>null</td><td>0</td></tr><tr><td>0</td><td>s3://&mldr;/dt=20210104/00000-0-a3bb1927-88eb-4f1c-bc6e-19076b0d952e-00001.parquet</td><td>PARQUET</td><td>{20210104}</td><td>14</td><td>2444</td><td>{1 -> 94, 2 -> 17}</td><td>{1 -> 14, 2 -> 14}</td><td>{1 -> 0, 2 -> 0}</td><td>{}</td><td>{1 -> 1, 2 -> 20210104}</td><td>{1 -> 3, 2 -> 20210104}</td><td>null</td><td>[4]</td><td>null</td><td>0</td></tr></tbody></table><h4 id=all-manifests>All Manifests</h4><p>To show all of the table&rsquo;s manifest files:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=display:flex><span><span style=color:#66d9ef>SELECT</span> <span style=color:#f92672>*</span> <span style=color:#66d9ef>FROM</span> prod.db.<span style=color:#66d9ef>table</span><span style=color:#960050;background-color:#1e0010>$</span>all_manifests;
</span></span></code></pre></div><table><thead><tr><th>path</th><th>length</th><th>partition_spec_id</th><th>added_snapshot_id</th><th>added_data_files_count</th><th>existing_data_files_count</th><th>deleted_data_files_count</th><th>partition_summaries</th></tr></thead><tbody><tr><td>s3://&mldr;/metadata/a85f78c5-3222-4b37-b7e4-faf944425d48-m0.avro</td><td>6376</td><td>0</td><td>6272782676904868561</td><td>2</td><td>0</td><td>0</td><td>[{false, false, 20210101, 20210101}]</td></tr></tbody></table><p>Note:</p><ol><li>Fields within <code>partition_summaries</code> column of the manifests table correspond to <code>field_summary</code> structs within <a href=../../../spec#manifest-lists>manifest list</a>, with the following order:<ul><li><code>contains_null</code></li><li><code>contains_nan</code></li><li><code>lower_bound</code></li><li><code>upper_bound</code></li></ul></li><li><code>contains_nan</code> could return null, which indicates that this information is not available from the file&rsquo;s metadata.
This usually occurs when reading from V1 table, where <code>contains_nan</code> is not populated.</li></ol><h3 id=references>References</h3><p>To show a table&rsquo;s known snapshot references:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=display:flex><span><span style=color:#66d9ef>SELECT</span> <span style=color:#f92672>*</span> <span style=color:#66d9ef>FROM</span> prod.db.<span style=color:#66d9ef>table</span><span style=color:#960050;background-color:#1e0010>$</span>refs;
</span></span></code></pre></div><table><thead><tr><th>name</th><th>type</th><th>snapshot_id</th><th>max_reference_age_in_ms</th><th>min_snapshots_to_keep</th><th>max_snapshot_age_in_ms</th></tr></thead><tbody><tr><td>main</td><td>BRANCH</td><td>4686954189838128572</td><td>10</td><td>20</td><td>30</td></tr><tr><td>testTag</td><td>TAG</td><td>4686954189838128572</td><td>10</td><td>null</td><td>null</td></tr></tbody></table></div><div id=toc class=markdown-body><div id=full><nav id=TableOfContents><ul><li><a href=#reading-with-sql>Reading with SQL</a><ul><li><a href=#flink-batch-read>Flink batch read</a></li><li><a href=#flink-streaming-read>Flink streaming read</a></li><li><a href=#flip-27-source-for-sql>FLIP-27 source for SQL</a></li><li><a href=#reading-branches-and-tags-with-sql>Reading branches and tags with SQL</a></li></ul></li><li><a href=#reading-with-datastream>Reading with DataStream</a><ul><li><a href=#batch-read>Batch Read</a></li><li><a href=#streaming-read>Streaming read</a></li></ul></li><li><a href=#reading-with-datastream-flip-27-source>Reading with DataStream (FLIP-27 source)</a><ul><li><a href=#batch-read-1>Batch Read</a></li><li><a href=#streaming-read-1>Streaming read</a></li><li><a href=#reading-branches-and-tags-with-datastream>Reading branches and tags with DataStream</a></li><li><a href=#read-as-avro-genericrecord>Read as Avro GenericRecord</a></li></ul></li><li><a href=#options>Options</a><ul><li><a href=#read-options>Read options</a></li></ul></li><li><a href=#inspecting-tables>Inspecting tables</a><ul><li><a href=#history>History</a></li><li><a href=#metadata-log-entries>Metadata Log Entries</a></li><li><a href=#snapshots>Snapshots</a></li><li><a href=#files>Files</a></li><li><a href=#manifests>Manifests</a></li><li><a href=#partitions>Partitions</a></li><li><a href=#all-metadata-tables>All Metadata Tables</a></li><li><a href=#references>References</a></li></ul></li></ul></nav></div></div></div></div></section></body><script src=https://iceberg.apache.org/docs/fd-update-latestt//js/jquery-1.11.0.js></script><script src=https://iceberg.apache.org/docs/fd-update-latestt//js/jquery.easing.min.js></script><script type=text/javascript src=https://iceberg.apache.org/docs/fd-update-latestt//js/search.js></script><script src=https://iceberg.apache.org/docs/fd-update-latestt//js/bootstrap.min.js></script><script src=https://iceberg.apache.org/docs/fd-update-latestt//js/iceberg-theme.js></script></html>