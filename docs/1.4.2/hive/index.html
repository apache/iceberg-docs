<!doctype html><html><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content><meta name=author content><title>Hive</title>
<link href=../css/bootstrap.css rel=stylesheet><link href=../css/markdown.css rel=stylesheet><link href=../css/katex.min.css rel=stylesheet><link href=../css/iceberg-theme.css rel=stylesheet><link href=../font-awesome-4.7.0/css/font-awesome.min.css rel=stylesheet type=text/css><link href="//fonts.googleapis.com/css?family=Lato:300,400,700,300italic,400italic,700italic" rel=stylesheet type=text/css><link href=../css/termynal.css rel=stylesheet></head><body><head><script>function addAnchor(e){e.insertAdjacentHTML("beforeend",`<a href="#${e.id}" class="anchortag" ariaLabel="Anchor"> ðŸ”— </a>`)}document.addEventListener("DOMContentLoaded",function(){var e=document.querySelectorAll("h1[id], h2[id], h3[id], h4[id]");e&&e.forEach(addAnchor)})</script></head><nav class="navbar navbar-default" role=navigation><topsection><div class=navbar-fixed-top><div><button type=button class=navbar-toggle data-toggle=collapse data-target=div.sidebar>
<span class=sr-only>Toggle navigation</span>
<span class=icon-bar></span>
<span class=icon-bar></span>
<span class=icon-bar></span>
</button>
<a class="page-scroll navbar-brand" href=https://iceberg.apache.org/><img class=top-navbar-logo src=https://iceberg.apache.org/docs/1.4.2//img/iceberg-logo-icon.png> Apache Iceberg</a></div><div><input type=search class=form-control id=search-input placeholder=Search... maxlength=64 data-hotkeys=s/></div><div class=versions-dropdown><span>1.4.1</span> <i class="fa fa-chevron-down"></i><div class=versions-dropdown-content><ul><li class=versions-dropdown-selection><a href=https://iceberg.apache.org/docs/1.4.2/../latest>latest</a></li><li class=versions-dropdown-selection><a href=https://iceberg.apache.org/docs/1.4.2/../1.4.1>1.4.1</a></li><li class=versions-dropdown-selection><a href=https://iceberg.apache.org/docs/1.4.2/../1.4.0>1.4.0</a></li><li class=versions-dropdown-selection><a href=https://iceberg.apache.org/docs/1.4.2/../1.3.1>1.3.1</a></li><li class=versions-dropdown-selection><a href=https://iceberg.apache.org/docs/1.4.2/../1.3.0>1.3.0</a></li><li class=versions-dropdown-selection><a href=https://iceberg.apache.org/docs/1.4.2/../1.2.1>1.2.1</a></li><li class=versions-dropdown-selection><a href=https://iceberg.apache.org/docs/1.4.2/../1.2.0>1.2.0</a></li><li class=versions-dropdown-selection><a href=https://iceberg.apache.org/docs/1.4.2/../1.1.0>1.1.0</a></li><li class=versions-dropdown-selection><a href=https://iceberg.apache.org/docs/1.4.2/../1.0.0>1.0.0</a></li><li class=versions-dropdown-selection><a href=https://iceberg.apache.org/docs/1.4.2/../0.14.1>0.14.1</a></li><li class=versions-dropdown-selection><a href=https://iceberg.apache.org/docs/1.4.2/../0.14.0>0.14.0</a></li><li class=versions-dropdown-selection><a href=https://iceberg.apache.org/docs/1.4.2/../0.13.2>0.13.2</a></li><li class=versions-dropdown-selection><a href=https://iceberg.apache.org/docs/1.4.2/../0.13.1>0.13.1</a></li><li class=versions-dropdown-selection><a href=https://iceberg.apache.org/docs/1.4.2/../0.13.0>0.13.0</a></li><li class=versions-dropdown-selection><a href=https://iceberg.apache.org/docs/1.4.2/../0.12.1>0.12.1</a></li></ul></div></div></div><div class="navbar-menu-fixed-top navbar-pages-group"><div class=versions-dropdown><div class=topnav-page-selection><a href>Quickstart</a> <i class="fa fa-chevron-down"></i></div class="topnav-page-selection"><div class=versions-dropdown-content><ul><li class=topnav-page-selection><a id=active href=https://iceberg.apache.org/docs/1.4.2/../../hive-quickstart>Hive</a></li class="topnav-page-selection"><li class=topnav-page-selection><a href=https://iceberg.apache.org/docs/1.4.2/../../spark-quickstart>Spark</a></li class="topnav-page-selection"></ul></div></div><div class=topnav-page-selection><a id=active href=https://iceberg.apache.org/docs/1.4.2/../../docs/latest>Docs</a></div><div class=topnav-page-selection><a href=https://iceberg.apache.org/docs/1.4.2/../../releases>Releases</a></div class="topnav-page-selection"><div class=topnav-page-selection><a href=https://iceberg.apache.org/docs/1.4.2/../../roadmap>Roadmap</a></div class="topnav-page-selection"><div class=topnav-page-selection><a href=https://iceberg.apache.org/docs/1.4.2/../../blogs>Blogs</a></div class="topnav-page-selection"><div class=topnav-page-selection><a href=https://iceberg.apache.org/docs/1.4.2/../../talks>Talks</a></div class="topnav-page-selection"><div class=versions-dropdown><div class=topnav-page-selection><a href>Project</a> <i class="fa fa-chevron-down"></i></div class="topnav-page-selection"><div class=versions-dropdown-content><ul><li class=topnav-page-selection><a href=https://iceberg.apache.org/docs/1.4.2/../../community>Community</a></li class="topnav-page-selection"><li class=topnav-page-selection><a href=https://iceberg.apache.org/docs/1.4.2/../../spec>Spec</a></li class="topnav-page-selection"><li class=topnav-page-selection><a href=https://iceberg.apache.org/docs/1.4.2/../../view-spec>View Spec</a></li class="topnav-page-selection"><li class=topnav-page-selection><a href=https://iceberg.apache.org/docs/1.4.2/../../puffin-spec>Puffin Spec</a></li class="topnav-page-selection"><li class=topnav-page-selection><a href=https://iceberg.apache.org/docs/1.4.2/../../multi-engine-support>Multi-Engine Support</a></li class="topnav-page-selection"><li class=topnav-page-selection><a href=https://iceberg.apache.org/docs/1.4.2/../../how-to-release>How To Release</a></li class="topnav-page-selection"><li class=topnav-page-selection><a href=https://iceberg.apache.org/docs/1.4.2/../../terms>Terms</a></li class="topnav-page-selection"></ul></div></div><div class=versions-dropdown><div class=topnav-page-selection><a href>Concepts</a> <i class="fa fa-chevron-down"></i></div class="topnav-page-selection"><div class=versions-dropdown-content><ul><li class=topnav-page-selection><a href=https://iceberg.apache.org/docs/1.4.2/../../catalog>Catalogs</a></li class="topnav-page-selection"></ul></div></div><div class=versions-dropdown><div class=topnav-page-selection><a href>ASF</a> <i class="fa fa-chevron-down"></i></div class="topnav-page-selection"><div class=versions-dropdown-content><ul><li class=topnav-page-selection><a target=_blank href=https://www.apache.org/foundation/sponsorship.html>Donate</a></li class="topnav-page-selection"><li class=topnav-page-selection><a target=_blank href=https://www.apache.org/events/current-event.html>Events</a></li class="topnav-page-selection"><li class=topnav-page-selection><a target=_blank href=https://www.apache.org/licenses/>License</a></li class="topnav-page-selection"><li class=topnav-page-selection><a target=_blank href=https://www.apache.org/security/>Security</a></li class="topnav-page-selection"><li class=topnav-page-selection><a target=_blank href=https://www.apache.org/foundation/thanks.html>Sponsors</a></li class="topnav-page-selection"></ul></div></div><div class=topnav-page-selection><a href=https://github.com/apache/iceberg target=_blank><img src=https://iceberg.apache.org/docs/1.4.2//img/GitHub-Mark.png target=_blank class=top-navbar-logo></a></div><div class=topnav-page-selection><a href=https://join.slack.com/t/apache-iceberg/shared_invite/zt-2561tq9qr-UtISlHgsdY3Virs3Z2_btQ target=_blank><img src=https://iceberg.apache.org/docs/1.4.2//img/Slack_Mark_Web.png target=_blank class=top-navbar-logo></a></div></div></topsection></nav><section><div id=search-results-container><ul id=search-results></ul></div></section><body dir=ltr><section><div class="grid-container leftnav-and-toc"><div class="sidebar markdown-body"><div id=full><ul><li><a href=../><span>Introduction</span></a></li><li><a class="chevron-toggle collapsed" data-toggle=collapse data-parent=full href=#Tables><span>Tables</span>
<i class="fa fa-chevron-right"></i>
<i class="fa fa-chevron-down"></i></a></li><div id=Tables class=collapse><ul class=sub-menu><li><a href=../branching/>Branching and Tagging</a></li><li><a href=../configuration/>Configuration</a></li><li><a href=../evolution/>Evolution</a></li><li><a href=../maintenance/>Maintenance</a></li><li><a href=../metrics-reporting/>Metrics Reporting</a></li><li><a href=../partitioning/>Partitioning</a></li><li><a href=../performance/>Performance</a></li><li><a href=../reliability/>Reliability</a></li><li><a href=../schemas/>Schemas</a></li></ul></div><li><a class="chevron-toggle collapsed" data-toggle=collapse data-parent=full href=#Spark><span>Spark</span>
<i class="fa fa-chevron-right"></i>
<i class="fa fa-chevron-down"></i></a></li><div id=Spark class=collapse><ul class=sub-menu><li><a href=../getting-started/>Getting Started</a></li><li><a href=../spark-configuration/>Configuration</a></li><li><a href=../spark-ddl/>DDL</a></li><li><a href=../spark-procedures/>Procedures</a></li><li><a href=../spark-queries/>Queries</a></li><li><a href=../spark-structured-streaming/>Structured Streaming</a></li><li><a href=../spark-writes/>Writes</a></li></ul></div><li><a class="chevron-toggle collapsed" data-toggle=collapse data-parent=full href=#Flink><span>Flink</span>
<i class="fa fa-chevron-right"></i>
<i class="fa fa-chevron-down"></i></a></li><div id=Flink class=collapse><ul class=sub-menu><li><a href=../flink/>Flink Getting Started</a></li><li><a href=../flink-connector/>Flink Connector</a></li><li><a href=../flink-ddl/>Flink DDL</a></li><li><a href=../flink-queries/>Flink Queries</a></li><li><a href=../flink-writes/>Flink Writes</a></li><li><a href=../flink-actions/>Flink Actions</a></li><li><a href=../flink-configuration/>Flink Configuration</a></li></ul></div><li><a id=active href=../hive/><span>Hive</span></a></li><li><a target=_blank href=https://trino.io/docs/current/connector/iceberg.html><span>Trino</span></a></li><li><a target=_blank href=https://clickhouse.com/docs/en/engines/table-engines/integrations/iceberg><span>ClickHouse</span></a></li><li><a target=_blank href=https://prestodb.io/docs/current/connector/iceberg.html><span>Presto</span></a></li><li><a target=_blank href=https://docs.dremio.com/data-formats/apache-iceberg/><span>Dremio</span></a></li><li><a target=_blank href=https://docs.starrocks.io/en-us/latest/data_source/catalog/iceberg_catalog><span>StarRocks</span></a></li><li><a target=_blank href=https://docs.aws.amazon.com/athena/latest/ug/querying-iceberg.html><span>Amazon Athena</span></a></li><li><a target=_blank href=https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-iceberg-use-cluster.html><span>Amazon EMR</span></a></li><li><a target=_blank href=https://impala.apache.org/docs/build/html/topics/impala_iceberg.html><span>Impala</span></a></li><li><a target=_blank href=https://doris.apache.org/docs/dev/lakehouse/multi-catalog/iceberg><span>Doris</span></a></li><li><a class="chevron-toggle collapsed" data-toggle=collapse data-parent=full href=#Integrations><span>Integrations</span>
<i class="fa fa-chevron-right"></i>
<i class="fa fa-chevron-down"></i></a></li><div id=Integrations class=collapse><ul class=sub-menu><li><a href=../aws/>AWS</a></li><li><a href=../dell/>Dell</a></li><li><a href=../jdbc/>JDBC</a></li><li><a href=../nessie/>Nessie</a></li></ul></div><li><a class="chevron-toggle collapsed" data-toggle=collapse data-parent=full href=#API><span>API</span>
<i class="fa fa-chevron-right"></i>
<i class="fa fa-chevron-down"></i></a></li><div id=API class=collapse><ul class=sub-menu><li><a href=../java-api-quickstart/>Java Quickstart</a></li><li><a href=../api/>Java API</a></li><li><a href=../custom-catalog/>Java Custom Catalog</a></li></ul></div><li><a class="chevron-toggle collapsed" data-toggle=collapse data-parent=full href=#Migration><span>Migration</span>
<i class="fa fa-chevron-right"></i>
<i class="fa fa-chevron-down"></i></a></li><div id=Migration class=collapse><ul class=sub-menu><li><a href=../table-migration/>Overview</a></li><li><a href=../hive-migration/>Hive Migration</a></li><li><a href=../delta-lake-migration/>Delta Lake Migration</a></li></ul></div><li><a href=https://iceberg.apache.org/docs/1.4.2/../../javadoc/latest><span>Javadoc</span></a></li><li><a target=_blank href=https://py.iceberg.apache.org/><span>PyIceberg</span></a></li></div></div><div id=content class=markdown-body><div class=margin-for-toc><h1 id=hive>Hive</h1><p>Iceberg supports reading and writing Iceberg tables through <a href=https://hive.apache.org>Hive</a> by using
a <a href=https://cwiki.apache.org/confluence/display/Hive/StorageHandlers>StorageHandler</a>.</p><h2 id=feature-support>Feature support</h2><p>Iceberg compatibility with Hive 2.x and Hive 3.1.2/3 supports the following features:</p><ul><li>Creating a table</li><li>Dropping a table</li><li>Reading a table</li><li>Inserting into a table (INSERT INTO)</li></ul><div class=warning>DML operations work only with MapReduce execution engine.</div><p>With Hive version 4.0.0-alpha-2 and above, Iceberg integration when using HiveCatalog supports the following additional features:</p><ul><li>Altering a table with expiring snapshots.</li><li>Create a table like an existing table (CTLT table)</li><li>Support adding parquet compression type via Table properties <a href=https://spark.apache.org/docs/2.4.3/sql-data-sources-parquet.html#configuration>Compression types</a></li><li>Altering a table metadata location</li><li>Supporting table rollback</li><li>Honours sort orders on existing tables when writing a table <a href=https://iceberg.apache.org/spec/#sort-orders>Sort orders specification</a></li></ul><p>With Hive version 4.0.0-alpha-1 and above, Iceberg integration when using HiveCatalog supports the following additional features:</p><ul><li>Creating an Iceberg identity-partitioned table</li><li>Creating an Iceberg table with any partition spec, including the various transforms supported by Iceberg</li><li>Creating a table from an existing table (CTAS table)</li><li>Altering a table while keeping Iceberg and Hive schemas in sync</li><li>Altering the partition schema (updating columns)</li><li>Altering the partition schema by specifying partition transforms</li><li>Truncating a table</li><li>Migrating tables in Avro, Parquet, or ORC (Non-ACID) format to Iceberg</li><li>Reading the schema of a table</li><li>Querying Iceberg metadata tables</li><li>Time travel applications</li><li>Inserting into a table (INSERT INTO)</li><li>Inserting data overwriting existing data (INSERT OVERWRITE)</li></ul><div class=warning>DML operations work only with Tez execution engine.</div><h2 id=enabling-iceberg-support-in-hive>Enabling Iceberg support in Hive</h2><p>Hive 4 comes with <code>hive-iceberg</code> that ships Iceberg, so no additional downloads or jars are needed. For older versions of Hive a runtime jar has to be added.</p><h3 id=hive-400-beta-1>Hive 4.0.0-beta-1</h3><p>Hive 4.0.0-beta-1 comes with the Iceberg 1.3.0 included.</p><h3 id=hive-400-alpha-2>Hive 4.0.0-alpha-2</h3><p>Hive 4.0.0-alpha-2 comes with the Iceberg 0.14.1 included.</p><h3 id=hive-400-alpha-1>Hive 4.0.0-alpha-1</h3><p>Hive 4.0.0-alpha-1 comes with the Iceberg 0.13.1 included.</p><h3 id=hive-23x-hive-31x>Hive 2.3.x, Hive 3.1.x</h3><p>In order to use Hive 2.3.x or Hive 3.1.x, you must load the Iceberg-Hive runtime jar and enable Iceberg support, either globally or for an individual table using a table property.</p><h4 id=loading-runtime-jar>Loading runtime jar</h4><p>To enable Iceberg support in Hive, the <code>HiveIcebergStorageHandler</code> and supporting classes need to be made available on
Hive&rsquo;s classpath. These are provided by the <code>iceberg-hive-runtime</code> jar file. For example, if using the Hive shell, this
can be achieved by issuing a statement like so:</p><pre tabindex=0><code>add jar /path/to/iceberg-hive-runtime.jar;
</code></pre><p>There are many others ways to achieve this including adding the jar file to Hive&rsquo;s auxiliary classpath so it is
available by default. Please refer to Hive&rsquo;s documentation for more information.</p><h4 id=enabling-support>Enabling support</h4><p>If the Iceberg storage handler is not in Hive&rsquo;s classpath, then Hive cannot load or update the metadata for an Iceberg
table when the storage handler is set. To avoid the appearance of broken tables in Hive, Iceberg will not add the
storage handler to a table unless Hive support is enabled. The storage handler is kept in sync (added or removed) every
time Hive engine support for the table is updated, i.e. turned on or off in the table properties. There are two ways to
enable Hive support: globally in Hadoop Configuration and per-table using a table property.</p><h5 id=hadoop-configuration>Hadoop configuration</h5><p>To enable Hive support globally for an application, set <code>iceberg.engine.hive.enabled=true</code> in its Hadoop configuration.
For example, setting this in the <code>hive-site.xml</code> loaded by Spark will enable the storage handler for all tables created
by Spark.</p><div class=danger>Starting with Apache Iceberg <code>0.11.0</code>, when using Hive with Tez you also have to disable
vectorization (<code>hive.vectorized.execution.enabled=false</code>).</div><h5 id=table-property-configuration>Table property configuration</h5><p>Alternatively, the property <code>engine.hive.enabled</code> can be set to <code>true</code> and added to the table properties when creating
the Iceberg table. Here is an example of doing it programmatically:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-java data-lang=java><span style=display:flex><span>Catalog catalog<span style=color:#f92672>=</span>...;
</span></span><span style=display:flex><span>    Map<span style=color:#f92672>&lt;</span>String, String<span style=color:#f92672>&gt;</span> tableProperties<span style=color:#f92672>=</span>Maps.<span style=color:#a6e22e>newHashMap</span>();
</span></span><span style=display:flex><span>    tableProperties.<span style=color:#a6e22e>put</span>(TableProperties.<span style=color:#a6e22e>ENGINE_HIVE_ENABLED</span>,<span style=color:#e6db74>&#34;true&#34;</span>); <span style=color:#75715e>// engine.hive.enabled=true</span>
</span></span><span style=display:flex><span>    catalog.<span style=color:#a6e22e>createTable</span>(tableId,schema,spec,tableProperties);
</span></span></code></pre></div><p>The table level configuration overrides the global Hadoop configuration.</p><h5 id=hive-on-tez-configuration>Hive on Tez configuration</h5><p>To use the Tez engine on Hive <code>3.1.2</code> or later, Tez needs to be upgraded to >= <code>0.10.1</code> which contains a necessary fix <a href=https://issues.apache.org/jira/browse/TEZ-4248>TEZ-4248</a>.</p><p>To use the Tez engine on Hive <code>2.3.x</code>, you will need to manually build Tez from the <code>branch-0.9</code> branch due to a
backwards incompatibility issue with Tez <code>0.10.1</code>.</p><p>In both cases, you will also need to set the following property in the <code>tez-site.xml</code> configuration file: <code>tez.mrreader.config.update.properties=hive.io.file.readcolumn.names,hive.io.file.readcolumn.ids</code>.</p><h2 id=catalog-management>Catalog Management</h2><h3 id=global-hive-catalog>Global Hive catalog</h3><p>From the Hive engine&rsquo;s perspective, there is only one global data catalog that is defined in the Hadoop configuration in
the runtime environment. In contrast, Iceberg supports multiple different data catalog types such as Hive, Hadoop, AWS
Glue, or custom catalog implementations. Iceberg also allows loading a table directly based on its path in the file
system. Those tables do not belong to any catalog. Users might want to read these cross-catalog and path-based tables
through the Hive engine for use cases like join.</p><p>To support this, a table in the Hive metastore can represent three different ways of loading an Iceberg table, depending
on the table&rsquo;s <code>iceberg.catalog</code> property:</p><ol><li>The table will be loaded using a <code>HiveCatalog</code> that corresponds to the metastore configured in the Hive environment
if no <code>iceberg.catalog</code> is set</li><li>The table will be loaded using a custom catalog if <code>iceberg.catalog</code> is set to a catalog name (see below)</li><li>The table can be loaded directly using the table&rsquo;s root location if <code>iceberg.catalog</code> is set
to <code>location_based_table</code></li></ol><p>For cases 2 and 3 above, users can create an overlay of an Iceberg table in the Hive metastore, so that different table
types can work together in the same Hive environment. See <a href=#create-external-table>CREATE EXTERNAL TABLE</a>
and <a href=#create-table>CREATE TABLE</a> for more details.</p><h3 id=custom-iceberg-catalogs>Custom Iceberg catalogs</h3><p>To globally register different catalogs, set the following Hadoop configurations:</p><table><thead><tr><th>Config Key</th><th>Description</th></tr></thead><tbody><tr><td>iceberg.catalog.&lt;catalog_name>.type</td><td>type of catalog: <code>hive</code>, <code>hadoop</code>, or left unset if using a custom catalog</td></tr><tr><td>iceberg.catalog.&lt;catalog_name>.catalog-impl</td><td>catalog implementation, must not be null if type is empty</td></tr><tr><td>iceberg.catalog.&lt;catalog_name>.&lt;key></td><td>any config key and value pairs for the catalog</td></tr></tbody></table><p>Here are some examples using Hive CLI:</p><p>Register a <code>HiveCatalog</code> called <code>another_hive</code>:</p><pre tabindex=0><code>SET iceberg.catalog.another_hive.type=hive;
SET iceberg.catalog.another_hive.uri=thrift://example.com:9083;
SET iceberg.catalog.another_hive.clients=10;
SET iceberg.catalog.another_hive.warehouse=hdfs://example.com:8020/warehouse;
</code></pre><p>Register a <code>HadoopCatalog</code> called <code>hadoop</code>:</p><pre tabindex=0><code>SET iceberg.catalog.hadoop.type=hadoop;
SET iceberg.catalog.hadoop.warehouse=hdfs://example.com:8020/warehouse;
</code></pre><p>Register an AWS <code>GlueCatalog</code> called <code>glue</code>:</p><pre tabindex=0><code>SET iceberg.catalog.glue.catalog-impl=org.apache.iceberg.aws.glue.GlueCatalog;
SET iceberg.catalog.glue.warehouse=s3://my-bucket/my/key/prefix;
SET iceberg.catalog.glue.lock.table=myGlueLockTable;
</code></pre><h2 id=ddl-commands>DDL Commands</h2><p>Not all the features below are supported with Hive 2.3.x and Hive 3.1.x. Please refer to the
<a href=#feature-support>Feature support</a> paragraph for further details.</p><p>One generally applicable difference is that Hive 4.0.0-alpha-1 provides the possibility to use
<code>STORED BY ICEBERG</code> instead of the old <code>STORED BY 'org.apache.iceberg.mr.hive.HiveIcebergStorageHandler'</code></p><h3 id=create-table>CREATE TABLE</h3><h4 id=non-partitioned-tables>Non partitioned tables</h4><p>The Hive <code>CREATE EXTERNAL TABLE</code> command creates an Iceberg table when you specify the storage handler as follows:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=display:flex><span><span style=color:#66d9ef>CREATE</span> <span style=color:#66d9ef>EXTERNAL</span> <span style=color:#66d9ef>TABLE</span> x (i int) STORED <span style=color:#66d9ef>BY</span> ICEBERG;
</span></span></code></pre></div><p>If you want to create external tables using CREATE TABLE, configure the MetaStoreMetadataTransformer on the cluster,
and <code>CREATE TABLE</code> commands are transformed to create external tables. For example:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=display:flex><span><span style=color:#66d9ef>CREATE</span> <span style=color:#66d9ef>TABLE</span> x (i int) STORED <span style=color:#66d9ef>BY</span> ICEBERG;
</span></span></code></pre></div><p>You can specify the default file format (Avro, Parquet, ORC) at the time of the table creation.
The default is Parquet:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=display:flex><span><span style=color:#66d9ef>CREATE</span> <span style=color:#66d9ef>TABLE</span> x (i int) STORED <span style=color:#66d9ef>BY</span> ICEBERG STORED <span style=color:#66d9ef>AS</span> ORC;
</span></span></code></pre></div><h4 id=partitioned-tables>Partitioned tables</h4><p>You can create Iceberg partitioned tables using a command familiar to those who create non-Iceberg tables:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=display:flex><span><span style=color:#66d9ef>CREATE</span> <span style=color:#66d9ef>TABLE</span> x (i int) PARTITIONED <span style=color:#66d9ef>BY</span> (j int) STORED <span style=color:#66d9ef>BY</span> ICEBERG;
</span></span></code></pre></div><div class=info>The resulting table does not create partitions in HMS, but instead, converts partition data into Iceberg identity partitions.</div><p>Use the DESCRIBE command to get information about the Iceberg identity partitions:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=display:flex><span><span style=color:#66d9ef>DESCRIBE</span> x;
</span></span></code></pre></div><p>The result is:</p><table><thead><tr><th>col_name</th><th>data_type</th><th>comment</th></tr></thead><tbody><tr><td>i</td><td>int</td><td></td></tr><tr><td>j</td><td>int</td><td></td></tr><tr><td></td><td>NULL</td><td>NULL</td></tr><tr><td># Partition Transform Information</td><td>NULL</td><td>NULL</td></tr><tr><td># col_name</td><td>transform_type</td><td>NULL</td></tr><tr><td>j</td><td>IDENTITY</td><td>NULL</td></tr></tbody></table><p>You can create Iceberg partitions using the following Iceberg partition specification syntax
(supported only from Hive 4.0.0-alpha-1):</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=display:flex><span><span style=color:#66d9ef>CREATE</span> <span style=color:#66d9ef>TABLE</span> x (i int, ts <span style=color:#66d9ef>timestamp</span>) PARTITIONED <span style=color:#66d9ef>BY</span> SPEC (<span style=color:#66d9ef>month</span>(ts), bucket(<span style=color:#ae81ff>2</span>, i)) STORED <span style=color:#66d9ef>AS</span> ICEBERG;
</span></span><span style=display:flex><span><span style=color:#66d9ef>DESCRIBE</span> x;
</span></span></code></pre></div><p>The result is:</p><table><thead><tr><th>col_name</th><th>data_type</th><th>comment</th></tr></thead><tbody><tr><td>i</td><td>int</td><td></td></tr><tr><td>ts</td><td>timestamp</td><td></td></tr><tr><td></td><td>NULL</td><td>NULL</td></tr><tr><td># Partition Transform Information</td><td>NULL</td><td>NULL</td></tr><tr><td># col_name</td><td>transform_type</td><td>NULL</td></tr><tr><td>ts</td><td>MONTH</td><td>NULL</td></tr><tr><td>i</td><td>BUCKET[2]</td><td>NULL</td></tr></tbody></table><p>The supported transformations for Hive are the same as for Spark:</p><ul><li>years(ts): partition by year</li><li>months(ts): partition by month</li><li>days(ts) or date(ts): equivalent to dateint partitioning</li><li>hours(ts) or date_hour(ts): equivalent to dateint and hour partitioning</li><li>bucket(N, col): partition by hashed value mod N buckets</li><li>truncate(L, col): partition by value truncated to L<ul><li>Strings are truncated to the given length</li><li>Integers and longs truncate to bins: truncate(10, i) produces partitions 0, 10, 20, 30,</li></ul></li></ul><div class=info>The resulting table does not create partitions in HMS, but instead, converts partition data into Iceberg partitions.</div><h3 id=create-table-as-select>CREATE TABLE AS SELECT</h3><p><code>CREATE TABLE AS SELECT</code> operation resembles the native Hive operation with a single important difference.
The Iceberg table and the corresponding Hive table are created at the beginning of the query execution.
The data is inserted / committed when the query finishes. So for a transient period the table already exists but contains no data.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=display:flex><span><span style=color:#66d9ef>CREATE</span> <span style=color:#66d9ef>TABLE</span> target PARTITIONED <span style=color:#66d9ef>BY</span> SPEC (<span style=color:#66d9ef>year</span>(year_field), identity_field) STORED <span style=color:#66d9ef>BY</span> ICEBERG <span style=color:#66d9ef>AS</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>SELECT</span> <span style=color:#f92672>*</span> <span style=color:#66d9ef>FROM</span> <span style=color:#66d9ef>source</span>;
</span></span></code></pre></div><h3 id=create-table-like-table>CREATE TABLE LIKE TABLE</h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=display:flex><span><span style=color:#66d9ef>CREATE</span> <span style=color:#66d9ef>TABLE</span> target <span style=color:#66d9ef>LIKE</span> <span style=color:#66d9ef>source</span> STORED <span style=color:#66d9ef>BY</span> ICEBERG;
</span></span></code></pre></div><h3 id=create-external-table-overlaying-an-existing-iceberg-table>CREATE EXTERNAL TABLE overlaying an existing Iceberg table</h3><p>The <code>CREATE EXTERNAL TABLE</code> command is used to overlay a Hive table &ldquo;on top of&rdquo; an existing Iceberg table. Iceberg
tables are created using either a <a href=../../../javadoc/1.4.1/index.html?org/apache/iceberg/catalog/Catalog.html><code>Catalog</code></a>, or an implementation of the <a href=../../../javadoc/1.4.1/index.html?org/apache/iceberg/Tables.html><code>Tables</code></a> interface, and Hive needs to be configured accordingly to
operate on these different types of table.</p><h4 id=hive-catalog-tables>Hive catalog tables</h4><p>As described before, tables created by the <code>HiveCatalog</code> with Hive engine feature enabled are directly visible by the
Hive engine, so there is no need to create an overlay.</p><h4 id=custom-catalog-tables>Custom catalog tables</h4><p>For a table in a registered catalog, specify the catalog name in the statement using table property <code>iceberg.catalog</code>.
For example, the SQL below creates an overlay for a table in a <code>hadoop</code> type catalog named <code>hadoop_cat</code>:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=display:flex><span><span style=color:#66d9ef>SET</span>
</span></span><span style=display:flex><span>iceberg.<span style=color:#66d9ef>catalog</span>.hadoop_cat.<span style=color:#66d9ef>type</span><span style=color:#f92672>=</span>hadoop;
</span></span><span style=display:flex><span><span style=color:#66d9ef>SET</span>
</span></span><span style=display:flex><span>iceberg.<span style=color:#66d9ef>catalog</span>.hadoop_cat.warehouse<span style=color:#f92672>=</span>hdfs:<span style=color:#f92672>//</span>example.com:<span style=color:#ae81ff>8020</span><span style=color:#f92672>/</span>hadoop_cat;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>CREATE</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>EXTERNAL</span> <span style=color:#66d9ef>TABLE</span> database_a.table_a
</span></span><span style=display:flex><span>STORED <span style=color:#66d9ef>BY</span> <span style=color:#e6db74>&#39;org.apache.iceberg.mr.hive.HiveIcebergStorageHandler&#39;</span>
</span></span><span style=display:flex><span>TBLPROPERTIES (<span style=color:#e6db74>&#39;iceberg.catalog&#39;</span><span style=color:#f92672>=</span><span style=color:#e6db74>&#39;hadoop_cat&#39;</span>);
</span></span></code></pre></div><p>When <code>iceberg.catalog</code> is missing from both table properties and the global Hadoop configuration, <code>HiveCatalog</code> will be
used as default.</p><h4 id=path-based-hadoop-tables>Path-based Hadoop tables</h4><p>Iceberg tables created using <code>HadoopTables</code> are stored entirely in a directory in a filesystem like HDFS. These tables
are considered to have no catalog. To indicate that, set <code>iceberg.catalog</code> property to <code>location_based_table</code>. For
example:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=display:flex><span><span style=color:#66d9ef>CREATE</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>EXTERNAL</span> <span style=color:#66d9ef>TABLE</span> table_a 
</span></span><span style=display:flex><span>STORED <span style=color:#66d9ef>BY</span> <span style=color:#e6db74>&#39;org.apache.iceberg.mr.hive.HiveIcebergStorageHandler&#39;</span> 
</span></span><span style=display:flex><span><span style=color:#66d9ef>LOCATION</span> <span style=color:#e6db74>&#39;hdfs://some_bucket/some_path/table_a&#39;</span>
</span></span><span style=display:flex><span>TBLPROPERTIES (<span style=color:#e6db74>&#39;iceberg.catalog&#39;</span><span style=color:#f92672>=</span><span style=color:#e6db74>&#39;location_based_table&#39;</span>);
</span></span></code></pre></div><h4 id=create-table-overlaying-an-existing-iceberg-table>CREATE TABLE overlaying an existing Iceberg table</h4><p>You can also create a new table that is managed by a custom catalog. For example, the following code creates a table in
a custom Hadoop catalog:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=display:flex><span><span style=color:#66d9ef>SET</span>
</span></span><span style=display:flex><span>iceberg.<span style=color:#66d9ef>catalog</span>.hadoop_cat.<span style=color:#66d9ef>type</span><span style=color:#f92672>=</span>hadoop;
</span></span><span style=display:flex><span><span style=color:#66d9ef>SET</span>
</span></span><span style=display:flex><span>iceberg.<span style=color:#66d9ef>catalog</span>.hadoop_cat.warehouse<span style=color:#f92672>=</span>hdfs:<span style=color:#f92672>//</span>example.com:<span style=color:#ae81ff>8020</span><span style=color:#f92672>/</span>hadoop_cat;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>CREATE</span> <span style=color:#66d9ef>TABLE</span> database_a.table_a
</span></span><span style=display:flex><span>(
</span></span><span style=display:flex><span>    id   bigint,
</span></span><span style=display:flex><span>    name string
</span></span><span style=display:flex><span>) PARTITIONED <span style=color:#66d9ef>BY</span> (
</span></span><span style=display:flex><span>  dept string
</span></span><span style=display:flex><span>) STORED <span style=color:#66d9ef>BY</span> <span style=color:#e6db74>&#39;org.apache.iceberg.mr.hive.HiveIcebergStorageHandler&#39;</span>
</span></span><span style=display:flex><span>TBLPROPERTIES (<span style=color:#e6db74>&#39;iceberg.catalog&#39;</span><span style=color:#f92672>=</span><span style=color:#e6db74>&#39;hadoop_cat&#39;</span>);
</span></span></code></pre></div><div class=danger>If the table to create already exists in the custom catalog, this will create a managed overlay
table. This means technically you can omit the <code>EXTERNAL</code> keyword when creating an overlay table. However, this is <strong>not
recommended</strong> because creating managed overlay tables could pose a risk to the shared data files in case of accidental
drop table commands from the Hive side, which would unintentionally remove all the data in the table.</div><h3 id=alter-table>ALTER TABLE</h3><h4 id=table-properties>Table properties</h4><p>For HiveCatalog tables the Iceberg table properties and the Hive table properties stored in HMS are kept in sync.</p><div class=info>IMPORTANT: This feature is not available for other Catalog implementations.</div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=display:flex><span><span style=color:#66d9ef>ALTER</span> <span style=color:#66d9ef>TABLE</span> t <span style=color:#66d9ef>SET</span> TBLPROPERTIES(<span style=color:#e6db74>&#39;...&#39;</span><span style=color:#f92672>=</span><span style=color:#e6db74>&#39;...&#39;</span>);
</span></span></code></pre></div><h4 id=schema-evolution>Schema evolution</h4><p>The Hive table schema is kept in sync with the Iceberg table. If an outside source (Impala/Spark/Java API/etc)
changes the schema, the Hive table immediately reflects the changes. You alter the table schema using Hive commands:</p><ul><li>Add a column</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=display:flex><span><span style=color:#66d9ef>ALTER</span> <span style=color:#66d9ef>TABLE</span> orders <span style=color:#66d9ef>ADD</span> COLUMNS (nickname string);
</span></span></code></pre></div><ul><li>Rename a column</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=display:flex><span><span style=color:#66d9ef>ALTER</span> <span style=color:#66d9ef>TABLE</span> orders CHANGE <span style=color:#66d9ef>COLUMN</span> item fruit string;
</span></span></code></pre></div><ul><li>Reorder columns</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=display:flex><span><span style=color:#66d9ef>ALTER</span> <span style=color:#66d9ef>TABLE</span> orders CHANGE <span style=color:#66d9ef>COLUMN</span> quantity quantity int <span style=color:#66d9ef>AFTER</span> price;
</span></span></code></pre></div><ul><li>Change a column type - only if the Iceberg defined the column type change as safe</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=display:flex><span><span style=color:#66d9ef>ALTER</span> <span style=color:#66d9ef>TABLE</span> orders CHANGE <span style=color:#66d9ef>COLUMN</span> price price long;
</span></span></code></pre></div><ul><li>Drop column by using REPLACE COLUMN to remove the old column</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=display:flex><span><span style=color:#66d9ef>ALTER</span> <span style=color:#66d9ef>TABLE</span> orders <span style=color:#66d9ef>REPLACE</span> COLUMNS (remaining string);
</span></span></code></pre></div><div class=info>Note, that dropping columns is only thing REPLACE COLUMNS can be used for
i.e. if columns are specified out-of-order an error will be thrown signalling this limitation.</div><h4 id=partition-evolution>Partition evolution</h4><p>You change the partitioning schema using the following commands:</p><ul><li>Change the partitioning schema to new identity partitions:</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=display:flex><span><span style=color:#66d9ef>ALTER</span> <span style=color:#66d9ef>TABLE</span> <span style=color:#66d9ef>default</span>.customers <span style=color:#66d9ef>SET</span> PARTITION SPEC (last_name);
</span></span></code></pre></div><ul><li>Alternatively, provide a partition specification:</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=display:flex><span><span style=color:#66d9ef>ALTER</span> <span style=color:#66d9ef>TABLE</span> <span style=color:#66d9ef>order</span> <span style=color:#66d9ef>SET</span> PARTITION SPEC (<span style=color:#66d9ef>month</span>(ts));
</span></span></code></pre></div><h4 id=table-migration>Table migration</h4><p>You can migrate Avro / Parquet / ORC external tables to Iceberg tables using the following command:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=display:flex><span><span style=color:#66d9ef>ALTER</span> <span style=color:#66d9ef>TABLE</span> t <span style=color:#66d9ef>SET</span> TBLPROPERTIES (<span style=color:#e6db74>&#39;storage_handler&#39;</span><span style=color:#f92672>=</span><span style=color:#e6db74>&#39;org.apache.iceberg.mr.hive.HiveIcebergStorageHandler&#39;</span>);
</span></span></code></pre></div><p>During the migration the data files are not changed, only the appropriate Iceberg metadata files are created.
After the migration, handle the table as a normal Iceberg table.</p><h3 id=truncate-table>TRUNCATE TABLE</h3><p>The following command truncates the Iceberg table:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=display:flex><span><span style=color:#66d9ef>TRUNCATE</span> <span style=color:#66d9ef>TABLE</span> t;
</span></span></code></pre></div><p>Using a partition specification is not allowed.</p><h3 id=drop-table>DROP TABLE</h3><p>Tables can be dropped using the <code>DROP TABLE</code> command:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=display:flex><span><span style=color:#66d9ef>DROP</span> <span style=color:#66d9ef>TABLE</span> [<span style=color:#66d9ef>IF</span> <span style=color:#66d9ef>EXISTS</span>] <span style=color:#66d9ef>table_name</span> [PURGE];
</span></span></code></pre></div><h3 id=metadata-location>METADATA LOCATION</h3><p>The metadata location (snapshot location) only can be changed if the new path contains the exact same metadata json.
It can be done only after migrating the table to Iceberg, the two operation cannot be done in one step.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=display:flex><span><span style=color:#66d9ef>ALTER</span> <span style=color:#66d9ef>TABLE</span> t <span style=color:#66d9ef>set</span> TBLPROPERTIES (<span style=color:#e6db74>&#39;metadata_location&#39;</span><span style=color:#f92672>=</span><span style=color:#e6db74>&#39;&lt;path&gt;/hivemetadata/00003-a1ada2b8-fc86-4b5b-8c91-400b6b46d0f2.metadata.json&#39;</span>);
</span></span></code></pre></div><h2 id=dml-commands>DML Commands</h2><h3 id=select>SELECT</h3><p>Select statements work the same on Iceberg tables in Hive. You will see the Iceberg benefits over Hive in compilation and execution:</p><ul><li><strong>No file system listings</strong> - especially important on blob stores, like S3</li><li><strong>No partition listing from</strong> the Metastore</li><li><strong>Advanced partition filtering</strong> - the partition keys are not needed in the queries when they could be calculated</li><li>Could handle <strong>higher number of partitions</strong> than normal Hive tables</li></ul><p>Here are the features highlights for Iceberg Hive read support:</p><ol><li><strong>Predicate pushdown</strong>: Pushdown of the Hive SQL <code>WHERE</code> clause has been implemented so that these filters are used at the Iceberg <code>TableScan</code> level as well as by the Parquet and ORC Readers.</li><li><strong>Column projection</strong>: Columns from the Hive SQL <code>SELECT</code> clause are projected down to the Iceberg readers to reduce the number of columns read.</li><li><strong>Hive query engines</strong>:<ul><li>With Hive 2.3.x, 3.1.x both the MapReduce and Tez query execution engines are supported.</li><li>With Hive 4.0.0-alpha-1 Tez query execution engine is supported.</li></ul></li></ol><p>Some of the advanced / little used optimizations are not yet implemented for Iceberg tables, so you should check your individual queries.
Also currently the statistics stored in the MetaStore are used for query planning. This is something we are planning to improve in the future.</p><h3 id=insert-into>INSERT INTO</h3><p>Hive supports the standard single-table INSERT INTO operation:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=display:flex><span><span style=color:#66d9ef>INSERT</span> <span style=color:#66d9ef>INTO</span> table_a
</span></span><span style=display:flex><span><span style=color:#66d9ef>VALUES</span> (<span style=color:#e6db74>&#39;a&#39;</span>, <span style=color:#ae81ff>1</span>);
</span></span><span style=display:flex><span><span style=color:#66d9ef>INSERT</span> <span style=color:#66d9ef>INTO</span> table_a
</span></span><span style=display:flex><span><span style=color:#66d9ef>SELECT</span>...;
</span></span></code></pre></div><p>Multi-table insert is also supported, but it will not be atomic. Commits occur one table at a time.
Partial changes will be visible during the commit process and failures can leave partial changes committed.
Changes within a single table will remain atomic.</p><p>Here is an example of inserting into multiple tables at once in Hive SQL:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=display:flex><span><span style=color:#66d9ef>FROM</span> customers
</span></span><span style=display:flex><span>   <span style=color:#66d9ef>INSERT</span> <span style=color:#66d9ef>INTO</span> target1 <span style=color:#66d9ef>SELECT</span> customer_id, first_name
</span></span><span style=display:flex><span>   <span style=color:#66d9ef>INSERT</span> <span style=color:#66d9ef>INTO</span> target2 <span style=color:#66d9ef>SELECT</span> last_name, customer_id;
</span></span></code></pre></div><h3 id=insert-overwrite>INSERT OVERWRITE</h3><p>INSERT OVERWRITE can replace data in the table with the result of a query. Overwrites are atomic operations for Iceberg tables.
For nonpartitioned tables the content of the table is always removed. For partitioned tables the partitions
that have rows produced by the SELECT query will be replaced.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=display:flex><span><span style=color:#66d9ef>INSERT</span> OVERWRITE <span style=color:#66d9ef>TABLE</span> target <span style=color:#66d9ef>SELECT</span> <span style=color:#f92672>*</span> <span style=color:#66d9ef>FROM</span> <span style=color:#66d9ef>source</span>;
</span></span></code></pre></div><h3 id=querying-metadata-tables>QUERYING METADATA TABLES</h3><p>Hive supports querying of the Iceberg Metadata tables. The tables could be used as normal
Hive tables, so it is possible to use projections / joins / filters / etc.
To reference a metadata table the full name of the table should be used, like:
&lt;DB_NAME>.&lt;TABLE_NAME>.&lt;METADATA_TABLE_NAME>.</p><p>Currently the following metadata tables are available in Hive:</p><ul><li>files</li><li>entries</li><li>snapshots</li><li>manifests</li><li>partitions</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=display:flex><span><span style=color:#66d9ef>SELECT</span> <span style=color:#f92672>*</span> <span style=color:#66d9ef>FROM</span> <span style=color:#66d9ef>default</span>.table_a.files;
</span></span></code></pre></div><h3 id=timetravel>TIMETRAVEL</h3><p>Hive supports snapshot id based and time base timetravel queries.
For these views it is possible to use projections / joins / filters / etc.
The function is available with the following syntax:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=display:flex><span><span style=color:#66d9ef>SELECT</span> <span style=color:#f92672>*</span> <span style=color:#66d9ef>FROM</span> table_a <span style=color:#66d9ef>FOR</span> SYSTEM_TIME <span style=color:#66d9ef>AS</span> <span style=color:#66d9ef>OF</span> <span style=color:#e6db74>&#39;2021-08-09 10:35:57&#39;</span>;
</span></span><span style=display:flex><span><span style=color:#66d9ef>SELECT</span> <span style=color:#f92672>*</span> <span style=color:#66d9ef>FROM</span> table_a <span style=color:#66d9ef>FOR</span> SYSTEM_VERSION <span style=color:#66d9ef>AS</span> <span style=color:#66d9ef>OF</span> <span style=color:#ae81ff>1234567</span>;
</span></span></code></pre></div><p>You can expire snapshots of an Iceberg table using an ALTER TABLE query from Hive. You should periodically expire snapshots to delete data files that is no longer needed, and reduce the size of table metadata.</p><p>Each write to an Iceberg table from Hive creates a new snapshot, or version, of a table. Snapshots can be used for time-travel queries, or the table can be rolled back to any valid snapshot. Snapshots accumulate until they are expired by the expire_snapshots operation.
Enter a query to expire snapshots having the following timestamp: <code>2021-12-09 05:39:18.689000000</code></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=display:flex><span><span style=color:#66d9ef>ALTER</span> <span style=color:#66d9ef>TABLE</span> test_table <span style=color:#66d9ef>EXECUTE</span> expire_snapshots(<span style=color:#e6db74>&#39;2021-12-09 05:39:18.689000000&#39;</span>);
</span></span></code></pre></div><h3 id=type-compatibility>Type compatibility</h3><p>Hive and Iceberg support different set of types. Iceberg can perform type conversion automatically, but not for all
combinations, so you may want to understand the type conversion in Iceberg in prior to design the types of columns in
your tables. You can enable auto-conversion through Hadoop configuration (not enabled by default):</p><table><thead><tr><th>Config key</th><th>Default</th><th>Description</th></tr></thead><tbody><tr><td>iceberg.mr.schema.auto.conversion</td><td>false</td><td>if Hive should perform type auto-conversion</td></tr></tbody></table><h3 id=hive-type-to-iceberg-type>Hive type to Iceberg type</h3><p>This type conversion table describes how Hive types are converted to the Iceberg types. The conversion applies on both
creating Iceberg table and writing to Iceberg table via Hive.</p><table><thead><tr><th>Hive</th><th>Iceberg</th><th>Notes</th></tr></thead><tbody><tr><td>boolean</td><td>boolean</td><td></td></tr><tr><td>short</td><td>integer</td><td>auto-conversion</td></tr><tr><td>byte</td><td>integer</td><td>auto-conversion</td></tr><tr><td>integer</td><td>integer</td><td></td></tr><tr><td>long</td><td>long</td><td></td></tr><tr><td>float</td><td>float</td><td></td></tr><tr><td>double</td><td>double</td><td></td></tr><tr><td>date</td><td>date</td><td></td></tr><tr><td>timestamp</td><td>timestamp without timezone</td><td></td></tr><tr><td>timestamplocaltz</td><td>timestamp with timezone</td><td>Hive 3 only</td></tr><tr><td>interval_year_month</td><td></td><td>not supported</td></tr><tr><td>interval_day_time</td><td></td><td>not supported</td></tr><tr><td>char</td><td>string</td><td>auto-conversion</td></tr><tr><td>varchar</td><td>string</td><td>auto-conversion</td></tr><tr><td>string</td><td>string</td><td></td></tr><tr><td>binary</td><td>binary</td><td></td></tr><tr><td>decimal</td><td>decimal</td><td></td></tr><tr><td>struct</td><td>struct</td><td></td></tr><tr><td>list</td><td>list</td><td></td></tr><tr><td>map</td><td>map</td><td></td></tr><tr><td>union</td><td></td><td>not supported</td></tr></tbody></table><h3 id=table-rollback>Table rollback</h3><p>Rolling back iceberg table&rsquo;s data to the state at an older table snapshot.</p><p>Rollback to the last snapshot before a specific timestamp</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=display:flex><span><span style=color:#66d9ef>ALTER</span> <span style=color:#66d9ef>TABLE</span> ice_t <span style=color:#66d9ef>EXECUTE</span> <span style=color:#66d9ef>ROLLBACK</span>(<span style=color:#e6db74>&#39;2022-05-12 00:00:00&#39;</span>)
</span></span></code></pre></div><p>Rollback to a specific snapshot ID</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=display:flex><span><span style=color:#66d9ef>ALTER</span> <span style=color:#66d9ef>TABLE</span> ice_t <span style=color:#66d9ef>EXECUTE</span> <span style=color:#66d9ef>ROLLBACK</span>(<span style=color:#ae81ff>1111</span>);
</span></span></code></pre></div></div><div id=toc class=markdown-body><div id=full><nav id=TableOfContents><ul><li><a href=#feature-support>Feature support</a></li><li><a href=#enabling-iceberg-support-in-hive>Enabling Iceberg support in Hive</a><ul><li><a href=#hive-400-beta-1>Hive 4.0.0-beta-1</a></li><li><a href=#hive-400-alpha-2>Hive 4.0.0-alpha-2</a></li><li><a href=#hive-400-alpha-1>Hive 4.0.0-alpha-1</a></li><li><a href=#hive-23x-hive-31x>Hive 2.3.x, Hive 3.1.x</a></li></ul></li><li><a href=#catalog-management>Catalog Management</a><ul><li><a href=#global-hive-catalog>Global Hive catalog</a></li><li><a href=#custom-iceberg-catalogs>Custom Iceberg catalogs</a></li></ul></li><li><a href=#ddl-commands>DDL Commands</a><ul><li><a href=#create-table>CREATE TABLE</a></li><li><a href=#create-table-as-select>CREATE TABLE AS SELECT</a></li><li><a href=#create-table-like-table>CREATE TABLE LIKE TABLE</a></li><li><a href=#create-external-table-overlaying-an-existing-iceberg-table>CREATE EXTERNAL TABLE overlaying an existing Iceberg table</a></li><li><a href=#alter-table>ALTER TABLE</a></li><li><a href=#truncate-table>TRUNCATE TABLE</a></li><li><a href=#drop-table>DROP TABLE</a></li><li><a href=#metadata-location>METADATA LOCATION</a></li></ul></li><li><a href=#dml-commands>DML Commands</a><ul><li><a href=#select>SELECT</a></li><li><a href=#insert-into>INSERT INTO</a></li><li><a href=#insert-overwrite>INSERT OVERWRITE</a></li><li><a href=#querying-metadata-tables>QUERYING METADATA TABLES</a></li><li><a href=#timetravel>TIMETRAVEL</a></li><li><a href=#type-compatibility>Type compatibility</a></li><li><a href=#hive-type-to-iceberg-type>Hive type to Iceberg type</a></li><li><a href=#table-rollback>Table rollback</a></li></ul></li></ul></nav></div></div></div></div></section></body><script src=https://iceberg.apache.org/docs/1.4.2//js/jquery-1.11.0.js></script><script src=https://iceberg.apache.org/docs/1.4.2//js/jquery.easing.min.js></script><script type=text/javascript src=https://iceberg.apache.org/docs/1.4.2//js/search.js></script><script src=https://iceberg.apache.org/docs/1.4.2//js/bootstrap.min.js></script><script src=https://iceberg.apache.org/docs/1.4.2//js/iceberg-theme.js></script></html>