<!doctype html><html><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content><meta name=author content><title>Spark and Iceberg Quickstart</title><link href=/css/bootstrap.css rel=stylesheet><link href=/css/markdown.css rel=stylesheet><link href=/css/katex.min.css rel=stylesheet><link href=/css/iceberg-theme.css rel=stylesheet><link href=/font-awesome-4.7.0/css/font-awesome.min.css rel=stylesheet type=text/css><link href="//fonts.googleapis.com/css?family=Lato:300,400,700,300italic,400italic,700italic" rel=stylesheet type=text/css><link href=/css/termynal.css rel=stylesheet></head><body><head><script>function addAnchor(e){e.insertAdjacentHTML("beforeend",`<a href="#${e.id}" class="anchortag" ariaLabel="Anchor"> ðŸ”— </a>`)}document.addEventListener("DOMContentLoaded",function(){var e=document.querySelectorAll("h1[id], h2[id], h3[id], h4[id]");e&&e.forEach(addAnchor)})</script></head><nav class="navbar navbar-default" role=navigation><topsection><div class=navbar-fixed-top><div><button type=button class=navbar-toggle data-toggle=collapse data-target=div.sidebar>
<span class=sr-only>Toggle navigation</span>
<span class=icon-bar></span>
<span class=icon-bar></span>
<span class=icon-bar></span></button>
<a class="page-scroll navbar-brand" href=https://iceberg.apache.org/><img class=top-navbar-logo src=https://iceberg.apache.org//img/iceberg-logo-icon.png> Apache Iceberg</a></div><div><input type=search class=form-control id=search-input placeholder=Search... maxlength=64 data-hotkeys=s/></div><div class=versions-dropdown><span>1.2.1</span> <i class="fa fa-chevron-down"></i><div class=versions-dropdown-content><ul><li class=versions-dropdown-selection><a href=/docs/latest>latest</a></li><li class=versions-dropdown-selection><a href=/docs/1.2.1>1.2.1</a></li><li class=versions-dropdown-selection><a href=/docs/1.2.0>1.2.0</a></li><li class=versions-dropdown-selection><a href=/docs/1.1.0>1.1.0</a></li><li class=versions-dropdown-selection><a href=/docs/1.0.0>1.0.0</a></li><li class=versions-dropdown-selection><a href=/docs/0.14.1>0.14.1</a></li><li class=versions-dropdown-selection><a href=/docs/0.14.0>0.14.0</a></li><li class=versions-dropdown-selection><a href=/docs/0.13.2>0.13.2</a></li><li class=versions-dropdown-selection><a href=/docs/0.13.1>0.13.1</a></li><li class=versions-dropdown-selection><a href=/docs/0.13.0>0.13.0</a></li><li class=versions-dropdown-selection><a href=/docs/0.12.1>0.12.1</a></li></ul></div></div></div><div class="navbar-menu-fixed-top navbar-pages-group"><div class=topnav-page-selection><a href=/spark-quickstart>Quickstart</a></div class="topnav-page-selection"><div class=topnav-page-selection><a href=/docs/latest>Docs</a></div class="topnav-page-selection"><div class=topnav-page-selection><a href=/releases>Releases</a></div class="topnav-page-selection"><div class=topnav-page-selection><a href=/roadmap>Roadmap</a></div class="topnav-page-selection"><div class=topnav-page-selection><a href=/blogs>Blogs</a></div class="topnav-page-selection"><div class=topnav-page-selection><a href=/talks>Talks</a></div class="topnav-page-selection"><div class=topnav-page-selection><a href=/vendors>Vendors</a></div class="topnav-page-selection"><div class=versions-dropdown><div class=topnav-page-selection><a href>Project</a> <i class="fa fa-chevron-down"></i></div class="topnav-page-selection"><div class=versions-dropdown-content><ul><li class=topnav-page-selection><a href=/community>Join</a></li class="topnav-page-selection"><li class=topnav-page-selection><a href=/spec>Spec</a></li class="topnav-page-selection"><li class=topnav-page-selection><a href=/view-spec>View Spec</a></li class="topnav-page-selection"><li class=topnav-page-selection><a href=/puffin-spec>Puffin Spec</a></li class="topnav-page-selection"><li class=topnav-page-selection><a href=/multi-engine-support>Multi-Engine Support</a></li class="topnav-page-selection"><li class=topnav-page-selection><a href=/how-to-release>How To Release</a></li class="topnav-page-selection"><li class=topnav-page-selection><a href=/terms>Terms</a></li class="topnav-page-selection"></ul></div></div><div class=versions-dropdown><div class=topnav-page-selection><a href>ASF</a> <i class="fa fa-chevron-down"></i></div class="topnav-page-selection"><div class=versions-dropdown-content><ul><li class=topnav-page-selection><a target=_blank href=https://www.apache.org/foundation/sponsorship.html>Donate</a></li class="topnav-page-selection"><li class=topnav-page-selection><a target=_blank href=https://www.apache.org/events/current-event.html>Events</a></li class="topnav-page-selection"><li class=topnav-page-selection><a target=_blank href=https://www.apache.org/licenses/>License</a></li class="topnav-page-selection"><li class=topnav-page-selection><a target=_blank href=https://www.apache.org/security/>Security</a></li class="topnav-page-selection"><li class=topnav-page-selection><a target=_blank href=https://www.apache.org/foundation/thanks.html>Sponsors</a></li class="topnav-page-selection"></ul></div></div><div class=topnav-page-selection><a href=https://github.com/apache/iceberg target=_blank><img src=https://iceberg.apache.org//img/GitHub-Mark.png target=_blank class=top-navbar-logo></a></div><div class=topnav-page-selection><a href=https://join.slack.com/t/apache-iceberg/shared_invite/zt-1oj35f7yc-wuTEhvkiqjGLje83B7rG8A target=_blank><img src=https://iceberg.apache.org//img/Slack_Mark_Web.png target=_blank class=top-navbar-logo></a></div></div></topsection></nav><section><div id=search-results-container><ul id=search-results></ul></div></section><body dir=" ltr"><section><div class="grid-container content-only"><div id=content class=markdown-body><div class=margin-without-toc><h2 id=spark-and-iceberg-quickstart>Spark and Iceberg Quickstart</h2><p>This guide will get you up and running with an Iceberg and Spark environment, including sample code to
highlight some powerful features. You can learn more about Iceberg&rsquo;s Spark runtime by checking out the <a href=../docs/latest/spark-ddl/>Spark</a> section.</p><ul><li><a href=#docker-compose>Docker-Compose</a></li><li><a href=#creating-a-table>Creating a table</a></li><li><a href=#writing-data-to-a-table>Writing Data to a Table</a></li><li><a href=#reading-data-from-a-table>Reading Data from a Table</a></li><li><a href=#adding-a-catalog>Adding A Catalog</a></li><li><a href=#next-steps>Next Steps</a></li></ul><h3 id=docker-compose>Docker-Compose</h3><p>The fastest way to get started is to use a docker-compose file that uses the <a href=https://hub.docker.com/r/tabulario/spark-iceberg>tabulario/spark-iceberg</a> image
which contains a local Spark cluster with a configured Iceberg catalog. To use this, you&rsquo;ll need to install the <a href=https://docs.docker.com/get-docker/>Docker CLI</a> as well as the <a href=https://github.com/docker/compose-cli/blob/main/INSTALL.md>Docker Compose CLI</a>.</p><p>Once you have those, save the yaml below into a file named <code>docker-compose.yml</code>:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#f92672>version</span>: <span style=color:#e6db74>&#34;3&#34;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>services</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>spark-iceberg</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>image</span>: <span style=color:#ae81ff>tabulario/spark-iceberg</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>container_name</span>: <span style=color:#ae81ff>spark-iceberg</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>build</span>: <span style=color:#ae81ff>spark/</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>networks</span>:
</span></span><span style=display:flex><span>      <span style=color:#f92672>iceberg_net</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>depends_on</span>:
</span></span><span style=display:flex><span>      - <span style=color:#ae81ff>rest</span>
</span></span><span style=display:flex><span>      - <span style=color:#ae81ff>minio</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>volumes</span>:
</span></span><span style=display:flex><span>      - <span style=color:#ae81ff>./warehouse:/home/iceberg/warehouse</span>
</span></span><span style=display:flex><span>      - <span style=color:#ae81ff>./notebooks:/home/iceberg/notebooks/notebooks</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>environment</span>:
</span></span><span style=display:flex><span>      - <span style=color:#ae81ff>AWS_ACCESS_KEY_ID=admin</span>
</span></span><span style=display:flex><span>      - <span style=color:#ae81ff>AWS_SECRET_ACCESS_KEY=password</span>
</span></span><span style=display:flex><span>      - <span style=color:#ae81ff>AWS_REGION=us-east-1</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>ports</span>:
</span></span><span style=display:flex><span>      - <span style=color:#ae81ff>8888</span>:<span style=color:#ae81ff>8888</span>
</span></span><span style=display:flex><span>      - <span style=color:#ae81ff>8080</span>:<span style=color:#ae81ff>8080</span>
</span></span><span style=display:flex><span>      - <span style=color:#ae81ff>10000</span>:<span style=color:#ae81ff>10000</span>
</span></span><span style=display:flex><span>      - <span style=color:#ae81ff>10001</span>:<span style=color:#ae81ff>10001</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>rest</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>image</span>: <span style=color:#ae81ff>tabulario/iceberg-rest</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>container_name</span>: <span style=color:#ae81ff>iceberg-rest</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>networks</span>:
</span></span><span style=display:flex><span>      <span style=color:#f92672>iceberg_net</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>ports</span>:
</span></span><span style=display:flex><span>      - <span style=color:#ae81ff>8181</span>:<span style=color:#ae81ff>8181</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>environment</span>:
</span></span><span style=display:flex><span>      - <span style=color:#ae81ff>AWS_ACCESS_KEY_ID=admin</span>
</span></span><span style=display:flex><span>      - <span style=color:#ae81ff>AWS_SECRET_ACCESS_KEY=password</span>
</span></span><span style=display:flex><span>      - <span style=color:#ae81ff>AWS_REGION=us-east-1</span>
</span></span><span style=display:flex><span>      - <span style=color:#ae81ff>CATALOG_WAREHOUSE=s3://warehouse/</span>
</span></span><span style=display:flex><span>      - <span style=color:#ae81ff>CATALOG_IO__IMPL=org.apache.iceberg.aws.s3.S3FileIO</span>
</span></span><span style=display:flex><span>      - <span style=color:#ae81ff>CATALOG_S3_ENDPOINT=http://minio:9000</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>minio</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>image</span>: <span style=color:#ae81ff>minio/minio</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>container_name</span>: <span style=color:#ae81ff>minio</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>environment</span>:
</span></span><span style=display:flex><span>      - <span style=color:#ae81ff>MINIO_ROOT_USER=admin</span>
</span></span><span style=display:flex><span>      - <span style=color:#ae81ff>MINIO_ROOT_PASSWORD=password</span>
</span></span><span style=display:flex><span>      - <span style=color:#ae81ff>MINIO_DOMAIN=minio</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>networks</span>:
</span></span><span style=display:flex><span>      <span style=color:#f92672>iceberg_net</span>:
</span></span><span style=display:flex><span>        <span style=color:#f92672>aliases</span>:
</span></span><span style=display:flex><span>          - <span style=color:#ae81ff>warehouse.minio</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>ports</span>:
</span></span><span style=display:flex><span>      - <span style=color:#ae81ff>9001</span>:<span style=color:#ae81ff>9001</span>
</span></span><span style=display:flex><span>      - <span style=color:#ae81ff>9000</span>:<span style=color:#ae81ff>9000</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>command</span>: [<span style=color:#e6db74>&#34;server&#34;</span>, <span style=color:#e6db74>&#34;/data&#34;</span>, <span style=color:#e6db74>&#34;--console-address&#34;</span>, <span style=color:#e6db74>&#34;:9001&#34;</span>]
</span></span><span style=display:flex><span>  <span style=color:#f92672>mc</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>depends_on</span>:
</span></span><span style=display:flex><span>      - <span style=color:#ae81ff>minio</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>image</span>: <span style=color:#ae81ff>minio/mc</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>container_name</span>: <span style=color:#ae81ff>mc</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>networks</span>:
</span></span><span style=display:flex><span>      <span style=color:#f92672>iceberg_net</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>environment</span>:
</span></span><span style=display:flex><span>      - <span style=color:#ae81ff>AWS_ACCESS_KEY_ID=admin</span>
</span></span><span style=display:flex><span>      - <span style=color:#ae81ff>AWS_SECRET_ACCESS_KEY=password</span>
</span></span><span style=display:flex><span>      - <span style=color:#ae81ff>AWS_REGION=us-east-1</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>entrypoint</span>: &gt;<span style=color:#e6db74>
</span></span></span><span style=display:flex><span><span style=color:#e6db74>      /bin/sh -c &#34;
</span></span></span><span style=display:flex><span><span style=color:#e6db74>      until (/usr/bin/mc config host add minio http://minio:9000 admin password) do echo &#39;...waiting...&#39; &amp;&amp; sleep 1; done;
</span></span></span><span style=display:flex><span><span style=color:#e6db74>      /usr/bin/mc rm -r --force minio/warehouse;
</span></span></span><span style=display:flex><span><span style=color:#e6db74>      /usr/bin/mc mb minio/warehouse;
</span></span></span><span style=display:flex><span><span style=color:#e6db74>      /usr/bin/mc policy set public minio/warehouse;
</span></span></span><span style=display:flex><span><span style=color:#e6db74>      tail -f /dev/null
</span></span></span><span style=display:flex><span><span style=color:#e6db74>      &#34;</span>      
</span></span><span style=display:flex><span><span style=color:#f92672>networks</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>iceberg_net</span>:
</span></span></code></pre></div><p>Next, start up the docker containers with this command:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>docker-compose up
</span></span></code></pre></div><p>You can then run any of the following commands to start a Spark session.</p><div class=codetabs><input id=spark-sql type=radio name=LaunchSparkClient onclick='selectExampleLanguage("spark-queries","spark-sql")'>
<label for=spark-sql>SparkSQL</label>
<input id=spark-shell type=radio name=LaunchSparkClient onclick='selectExampleLanguage("spark-queries","spark-shell")'>
<label for=spark-shell>Spark-Shell</label>
<input id=pyspark type=radio name=LaunchSparkClient onclick='selectExampleLanguage("spark-queries","pyspark")'>
<label for=pyspark>PySpark</label>
<codeblock class=spark-sql><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>docker exec -it spark-iceberg spark-sql
</span></span></code></pre></div></codeblock><codeblock class=spark-shell><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>docker exec -it spark-iceberg spark-shell
</span></span></code></pre></div></codeblock><codeblock class=pyspark><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>docker exec -it spark-iceberg pyspark
</span></span></code></pre></div></codeblock></div><div class=info>You can also launch a notebook server by running <code>docker exec -it spark-iceberg notebook</code>.
The notebook server will be available at <a href=http://localhost:8888>http://localhost:8888</a></div><h3 id=creating-a-table>Creating a table</h3><p>To create your first Iceberg table in Spark, run a <a href=../spark-ddl#create-table><code>CREATE TABLE</code></a> command. Let&rsquo;s create a table
using <code>demo.nyc.taxis</code> where <code>demo</code> is the catalog name, <code>nyc</code> is the database name, and <code>taxis</code> is the table name.</p><div class=codetabs><input id=spark-sql type=radio name=CreateATable onclick='selectExampleLanguage("spark-queries","spark-sql")'>
<label for=spark-sql>SparkSQL</label>
<input id=spark-shell type=radio name=CreateATable onclick='selectExampleLanguage("spark-queries","spark-shell")'>
<label for=spark-shell>Spark-Shell</label>
<input id=pyspark type=radio name=CreateATable onclick='selectExampleLanguage("spark-queries","pyspark")'>
<label for=pyspark>PySpark</label>
<codeblock class=spark-sql><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=display:flex><span><span style=color:#66d9ef>CREATE</span> <span style=color:#66d9ef>TABLE</span> demo.nyc.taxis
</span></span><span style=display:flex><span>(
</span></span><span style=display:flex><span>  vendor_id bigint,
</span></span><span style=display:flex><span>  trip_id bigint,
</span></span><span style=display:flex><span>  trip_distance float,
</span></span><span style=display:flex><span>  fare_amount double,
</span></span><span style=display:flex><span>  store_and_fwd_flag string
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>PARTITIONED <span style=color:#66d9ef>BY</span> (vendor_id);
</span></span></code></pre></div></codeblock><codeblock class=spark-shell><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-scala data-lang=scala><span style=display:flex><span><span style=color:#66d9ef>import</span> org.apache.spark.sql.types._
</span></span><span style=display:flex><span><span style=color:#66d9ef>import</span> org.apache.spark.sql.Row
</span></span><span style=display:flex><span><span style=color:#66d9ef>val</span> schema <span style=color:#66d9ef>=</span> <span style=color:#a6e22e>StructType</span><span style=color:#f92672>(</span> <span style=color:#a6e22e>Array</span><span style=color:#f92672>(</span>
</span></span><span style=display:flex><span>    <span style=color:#a6e22e>StructField</span><span style=color:#f92672>(</span><span style=color:#e6db74>&#34;vendor_id&#34;</span><span style=color:#f92672>,</span> <span style=color:#a6e22e>LongType</span><span style=color:#f92672>,</span><span style=color:#66d9ef>true</span><span style=color:#f92672>),</span>
</span></span><span style=display:flex><span>    <span style=color:#a6e22e>StructField</span><span style=color:#f92672>(</span><span style=color:#e6db74>&#34;trip_id&#34;</span><span style=color:#f92672>,</span> <span style=color:#a6e22e>LongType</span><span style=color:#f92672>,</span><span style=color:#66d9ef>true</span><span style=color:#f92672>),</span>
</span></span><span style=display:flex><span>    <span style=color:#a6e22e>StructField</span><span style=color:#f92672>(</span><span style=color:#e6db74>&#34;trip_distance&#34;</span><span style=color:#f92672>,</span> <span style=color:#a6e22e>FloatType</span><span style=color:#f92672>,</span><span style=color:#66d9ef>true</span><span style=color:#f92672>),</span>
</span></span><span style=display:flex><span>    <span style=color:#a6e22e>StructField</span><span style=color:#f92672>(</span><span style=color:#e6db74>&#34;fare_amount&#34;</span><span style=color:#f92672>,</span> <span style=color:#a6e22e>DoubleType</span><span style=color:#f92672>,</span><span style=color:#66d9ef>true</span><span style=color:#f92672>),</span>
</span></span><span style=display:flex><span>    <span style=color:#a6e22e>StructField</span><span style=color:#f92672>(</span><span style=color:#e6db74>&#34;store_and_fwd_flag&#34;</span><span style=color:#f92672>,</span> <span style=color:#a6e22e>StringType</span><span style=color:#f92672>,</span><span style=color:#66d9ef>true</span><span style=color:#f92672>)</span>
</span></span><span style=display:flex><span><span style=color:#f92672>))</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>val</span> df <span style=color:#66d9ef>=</span> spark<span style=color:#f92672>.</span>createDataFrame<span style=color:#f92672>(</span>spark<span style=color:#f92672>.</span>sparkContext<span style=color:#f92672>.</span>emptyRDD<span style=color:#f92672>[</span><span style=color:#66d9ef>Row</span><span style=color:#f92672>],</span>schema<span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>df<span style=color:#f92672>.</span>writeTo<span style=color:#f92672>(</span><span style=color:#e6db74>&#34;demo.nyc.taxis&#34;</span><span style=color:#f92672>).</span>create<span style=color:#f92672>()</span>
</span></span></code></pre></div></codeblock><codeblock class=pyspark><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-py data-lang=py><span style=display:flex><span><span style=color:#f92672>from</span> pyspark.sql.types <span style=color:#f92672>import</span> DoubleType, FloatType, LongType, StructType,StructField, StringType
</span></span><span style=display:flex><span>schema <span style=color:#f92672>=</span> StructType([
</span></span><span style=display:flex><span>  StructField(<span style=color:#e6db74>&#34;vendor_id&#34;</span>, LongType(), <span style=color:#66d9ef>True</span>),
</span></span><span style=display:flex><span>  StructField(<span style=color:#e6db74>&#34;trip_id&#34;</span>, LongType(), <span style=color:#66d9ef>True</span>),
</span></span><span style=display:flex><span>  StructField(<span style=color:#e6db74>&#34;trip_distance&#34;</span>, FloatType(), <span style=color:#66d9ef>True</span>),
</span></span><span style=display:flex><span>  StructField(<span style=color:#e6db74>&#34;fare_amount&#34;</span>, DoubleType(), <span style=color:#66d9ef>True</span>),
</span></span><span style=display:flex><span>  StructField(<span style=color:#e6db74>&#34;store_and_fwd_flag&#34;</span>, StringType(), <span style=color:#66d9ef>True</span>)
</span></span><span style=display:flex><span>])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>df <span style=color:#f92672>=</span> spark<span style=color:#f92672>.</span>createDataFrame([], schema)
</span></span><span style=display:flex><span>df<span style=color:#f92672>.</span>writeTo(<span style=color:#e6db74>&#34;demo.nyc.taxis&#34;</span>)<span style=color:#f92672>.</span>create()
</span></span></code></pre></div></codeblock></div><p>Iceberg catalogs support the full range of SQL DDL commands, including:</p><ul><li><a href=../spark-ddl#create-table><code>CREATE TABLE ... PARTITIONED BY</code></a></li><li><a href=../spark-ddl#create-table--as-select><code>CREATE TABLE ... AS SELECT</code></a></li><li><a href=../spark-ddl#alter-table><code>ALTER TABLE</code></a></li><li><a href=../spark-ddl#drop-table><code>DROP TABLE</code></a></li></ul><h3 id=writing-data-to-a-table>Writing Data to a Table</h3><p>Once your table is created, you can insert records.</p><div class=codetabs><input id=spark-sql type=radio name=InsertData onclick='selectExampleLanguage("spark-queries","spark-sql")'>
<label for=spark-sql>SparkSQL</label>
<input id=spark-shell type=radio name=InsertData onclick='selectExampleLanguage("spark-queries","spark-shell")'>
<label for=spark-shell>Spark-Shell</label>
<input id=pyspark type=radio name=InsertData onclick='selectExampleLanguage("spark-queries","pyspark")'>
<label for=pyspark>PySpark</label>
<codeblock class=spark-sql><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=display:flex><span><span style=color:#66d9ef>INSERT</span> <span style=color:#66d9ef>INTO</span> demo.nyc.taxis
</span></span><span style=display:flex><span><span style=color:#66d9ef>VALUES</span> (<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1000371</span>, <span style=color:#ae81ff>1</span>.<span style=color:#ae81ff>8</span>, <span style=color:#ae81ff>15</span>.<span style=color:#ae81ff>32</span>, <span style=color:#e6db74>&#39;N&#39;</span>), (<span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>1000372</span>, <span style=color:#ae81ff>2</span>.<span style=color:#ae81ff>5</span>, <span style=color:#ae81ff>22</span>.<span style=color:#ae81ff>15</span>, <span style=color:#e6db74>&#39;N&#39;</span>), (<span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>1000373</span>, <span style=color:#ae81ff>0</span>.<span style=color:#ae81ff>9</span>, <span style=color:#ae81ff>9</span>.<span style=color:#ae81ff>01</span>, <span style=color:#e6db74>&#39;N&#39;</span>), (<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1000374</span>, <span style=color:#ae81ff>8</span>.<span style=color:#ae81ff>4</span>, <span style=color:#ae81ff>42</span>.<span style=color:#ae81ff>13</span>, <span style=color:#e6db74>&#39;Y&#39;</span>);
</span></span></code></pre></div></codeblock><codeblock class=spark-shell><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-scala data-lang=scala><span style=display:flex><span><span style=color:#66d9ef>import</span> org.apache.spark.sql.Row
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>val</span> schema <span style=color:#66d9ef>=</span> spark<span style=color:#f92672>.</span>table<span style=color:#f92672>(</span><span style=color:#e6db74>&#34;demo.nyc.taxis&#34;</span><span style=color:#f92672>).</span>schema
</span></span><span style=display:flex><span><span style=color:#66d9ef>val</span> data <span style=color:#66d9ef>=</span> <span style=color:#a6e22e>Seq</span><span style=color:#f92672>(</span>
</span></span><span style=display:flex><span>    <span style=color:#a6e22e>Row</span><span style=color:#f92672>(</span><span style=color:#ae81ff>1</span><span style=color:#66d9ef>:</span> <span style=color:#66d9ef>Long</span><span style=color:#f92672>,</span> <span style=color:#ae81ff>1000371</span><span style=color:#66d9ef>:</span> <span style=color:#66d9ef>Long</span><span style=color:#f92672>,</span> <span style=color:#ae81ff>1.8f</span><span style=color:#66d9ef>:</span> <span style=color:#66d9ef>Float</span><span style=color:#f92672>,</span> <span style=color:#ae81ff>15.32</span><span style=color:#66d9ef>:</span> <span style=color:#66d9ef>Double</span><span style=color:#f92672>,</span> <span style=color:#e6db74>&#34;N&#34;</span><span style=color:#66d9ef>:</span> <span style=color:#66d9ef>String</span><span style=color:#f92672>),</span>
</span></span><span style=display:flex><span>    <span style=color:#a6e22e>Row</span><span style=color:#f92672>(</span><span style=color:#ae81ff>2</span><span style=color:#66d9ef>:</span> <span style=color:#66d9ef>Long</span><span style=color:#f92672>,</span> <span style=color:#ae81ff>1000372</span><span style=color:#66d9ef>:</span> <span style=color:#66d9ef>Long</span><span style=color:#f92672>,</span> <span style=color:#ae81ff>2.5f</span><span style=color:#66d9ef>:</span> <span style=color:#66d9ef>Float</span><span style=color:#f92672>,</span> <span style=color:#ae81ff>22.15</span><span style=color:#66d9ef>:</span> <span style=color:#66d9ef>Double</span><span style=color:#f92672>,</span> <span style=color:#e6db74>&#34;N&#34;</span><span style=color:#66d9ef>:</span> <span style=color:#66d9ef>String</span><span style=color:#f92672>),</span>
</span></span><span style=display:flex><span>    <span style=color:#a6e22e>Row</span><span style=color:#f92672>(</span><span style=color:#ae81ff>2</span><span style=color:#66d9ef>:</span> <span style=color:#66d9ef>Long</span><span style=color:#f92672>,</span> <span style=color:#ae81ff>1000373</span><span style=color:#66d9ef>:</span> <span style=color:#66d9ef>Long</span><span style=color:#f92672>,</span> <span style=color:#ae81ff>0.9f</span><span style=color:#66d9ef>:</span> <span style=color:#66d9ef>Float</span><span style=color:#f92672>,</span> <span style=color:#ae81ff>9.01</span><span style=color:#66d9ef>:</span> <span style=color:#66d9ef>Double</span><span style=color:#f92672>,</span> <span style=color:#e6db74>&#34;N&#34;</span><span style=color:#66d9ef>:</span> <span style=color:#66d9ef>String</span><span style=color:#f92672>),</span>
</span></span><span style=display:flex><span>    <span style=color:#a6e22e>Row</span><span style=color:#f92672>(</span><span style=color:#ae81ff>1</span><span style=color:#66d9ef>:</span> <span style=color:#66d9ef>Long</span><span style=color:#f92672>,</span> <span style=color:#ae81ff>1000374</span><span style=color:#66d9ef>:</span> <span style=color:#66d9ef>Long</span><span style=color:#f92672>,</span> <span style=color:#ae81ff>8.4f</span><span style=color:#66d9ef>:</span> <span style=color:#66d9ef>Float</span><span style=color:#f92672>,</span> <span style=color:#ae81ff>42.13</span><span style=color:#66d9ef>:</span> <span style=color:#66d9ef>Double</span><span style=color:#f92672>,</span> <span style=color:#e6db74>&#34;Y&#34;</span><span style=color:#66d9ef>:</span> <span style=color:#66d9ef>String</span><span style=color:#f92672>)</span>
</span></span><span style=display:flex><span><span style=color:#f92672>)</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>val</span> df <span style=color:#66d9ef>=</span> spark<span style=color:#f92672>.</span>createDataFrame<span style=color:#f92672>(</span>spark<span style=color:#f92672>.</span>sparkContext<span style=color:#f92672>.</span>parallelize<span style=color:#f92672>(</span>data<span style=color:#f92672>),</span> schema<span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>df<span style=color:#f92672>.</span>writeTo<span style=color:#f92672>(</span><span style=color:#e6db74>&#34;demo.nyc.taxis&#34;</span><span style=color:#f92672>).</span>append<span style=color:#f92672>()</span>
</span></span></code></pre></div></codeblock><codeblock class=pyspark><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-py data-lang=py><span style=display:flex><span>schema <span style=color:#f92672>=</span> spark<span style=color:#f92672>.</span>table(<span style=color:#e6db74>&#34;demo.nyc.taxis&#34;</span>)<span style=color:#f92672>.</span>schema
</span></span><span style=display:flex><span>data <span style=color:#f92672>=</span> [
</span></span><span style=display:flex><span>    (<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1000371</span>, <span style=color:#ae81ff>1.8</span>, <span style=color:#ae81ff>15.32</span>, <span style=color:#e6db74>&#34;N&#34;</span>),
</span></span><span style=display:flex><span>    (<span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>1000372</span>, <span style=color:#ae81ff>2.5</span>, <span style=color:#ae81ff>22.15</span>, <span style=color:#e6db74>&#34;N&#34;</span>),
</span></span><span style=display:flex><span>    (<span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>1000373</span>, <span style=color:#ae81ff>0.9</span>, <span style=color:#ae81ff>9.01</span>, <span style=color:#e6db74>&#34;N&#34;</span>),
</span></span><span style=display:flex><span>    (<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1000374</span>, <span style=color:#ae81ff>8.4</span>, <span style=color:#ae81ff>42.13</span>, <span style=color:#e6db74>&#34;Y&#34;</span>)
</span></span><span style=display:flex><span>  ]
</span></span><span style=display:flex><span>df <span style=color:#f92672>=</span> spark<span style=color:#f92672>.</span>createDataFrame(data, schema)
</span></span><span style=display:flex><span>df<span style=color:#f92672>.</span>writeTo(<span style=color:#e6db74>&#34;demo.nyc.taxis&#34;</span>)<span style=color:#f92672>.</span>append()
</span></span></code></pre></div></codeblock></div><h3 id=reading-data-from-a-table>Reading Data from a Table</h3><p>To read a table, simply use the Iceberg table&rsquo;s name.</p><div class=codetabs><input id=spark-sql type=radio name=SelectData onclick='selectExampleLanguage("spark-queries","spark-sql")'>
<label for=spark-sql>SparkSQL</label>
<input id=spark-shell type=radio name=SelectData onclick='selectExampleLanguage("spark-queries","spark-shell")'>
<label for=spark-shell>Spark-Shell</label>
<input id=pyspark type=radio name=SelectData onclick='selectExampleLanguage("spark-queries","pyspark")'>
<label for=pyspark>PySpark</label>
<codeblock class=spark-sql><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=display:flex><span><span style=color:#66d9ef>SELECT</span> <span style=color:#f92672>*</span> <span style=color:#66d9ef>FROM</span> demo.nyc.taxis;
</span></span></code></pre></div></codeblock><codeblock class=spark-shell><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-scala data-lang=scala><span style=display:flex><span><span style=color:#66d9ef>val</span> df <span style=color:#66d9ef>=</span> spark<span style=color:#f92672>.</span>table<span style=color:#f92672>(</span><span style=color:#e6db74>&#34;demo.nyc.taxis&#34;</span><span style=color:#f92672>).</span>show<span style=color:#f92672>()</span>
</span></span></code></pre></div></codeblock><codeblock class=pyspark><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-py data-lang=py><span style=display:flex><span>df <span style=color:#f92672>=</span> spark<span style=color:#f92672>.</span>table(<span style=color:#e6db74>&#34;demo.nyc.taxis&#34;</span>)<span style=color:#f92672>.</span>show()
</span></span></code></pre></div></codeblock></div><h3 id=adding-a-catalog>Adding A Catalog</h3><p>Iceberg has several catalog back-ends that can be used to track tables, like JDBC, Hive MetaStore and Glue.
Catalogs are configured using properties under <code>spark.sql.catalog.(catalog_name)</code>. In this guide,
we use JDBC, but you can follow these instructions to configure other catalog types. To learn more, check out
the <a href=../docs/latest/spark-configuration/#catalogs>Catalog</a> page in the Spark section.</p><p>This configuration creates a path-based catalog named <code>local</code> for tables under <code>$PWD/warehouse</code> and adds support for Iceberg tables to Spark&rsquo;s built-in catalog.</p><div class=codetabs><input id=cli type=radio name=AddingACatalog onclick='selectExampleLanguage("spark-init","cli")'>
<label for=cli>CLI</label>
<input id=spark-defaults type=radio name=AddingACatalog onclick='selectExampleLanguage("spark-init","spark-defaults")'>
<label for=spark-defaults>spark-defaults.conf</label>
<codeblock class=cli><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>spark-sql --packages org.apache.iceberg:iceberg-spark-runtime-3.2_2.12:1.2.1<span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    --conf spark.sql.extensions<span style=color:#f92672>=</span>org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    --conf spark.sql.catalog.spark_catalog<span style=color:#f92672>=</span>org.apache.iceberg.spark.SparkSessionCatalog <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    --conf spark.sql.catalog.spark_catalog.type<span style=color:#f92672>=</span>hive <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    --conf spark.sql.catalog.local<span style=color:#f92672>=</span>org.apache.iceberg.spark.SparkCatalog <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    --conf spark.sql.catalog.local.type<span style=color:#f92672>=</span>hadoop <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    --conf spark.sql.catalog.local.warehouse<span style=color:#f92672>=</span>$PWD/warehouse <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    --conf spark.sql.defaultCatalog<span style=color:#f92672>=</span>local
</span></span></code></pre></div></codeblock><codeblock class=spark-defaults><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>spark.jars.packages                                  org.apache.iceberg:iceberg-spark-runtime-3.2_2.12:1.2.1
</span></span><span style=display:flex><span>spark.sql.extensions                                 org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions
</span></span><span style=display:flex><span>spark.sql.catalog.spark_catalog                      org.apache.iceberg.spark.SparkSessionCatalog
</span></span><span style=display:flex><span>spark.sql.catalog.spark_catalog.type                 hive
</span></span><span style=display:flex><span>spark.sql.catalog.local                              org.apache.iceberg.spark.SparkCatalog
</span></span><span style=display:flex><span>spark.sql.catalog.local.type                         hadoop
</span></span><span style=display:flex><span>spark.sql.catalog.local.warehouse                    $PWD/warehouse
</span></span><span style=display:flex><span>spark.sql.defaultCatalog                             local
</span></span></code></pre></div></codeblock></div><div class=info>If your Iceberg catalog is not set as the default catalog, you will have to switch to it by executing <code>USE local;</code></div><h3 id=next-steps>Next steps</h3><h4 id=adding-iceberg-to-spark>Adding Iceberg to Spark</h4><p>If you already have a Spark environment, you can add Iceberg, using the <code>--packages</code> option.</p><div class=codetabs><input id=spark-sql type=radio name=AddIcebergToSpark onclick='selectExampleLanguage("spark-queries","spark-sql")'>
<label for=spark-sql>SparkSQL</label>
<input id=spark-shell type=radio name=AddIcebergToSpark onclick='selectExampleLanguage("spark-queries","spark-shell")'>
<label for=spark-shell>Spark-Shell</label>
<input id=pyspark type=radio name=AddIcebergToSpark onclick='selectExampleLanguage("spark-queries","pyspark")'>
<label for=pyspark>PySpark</label>
<codeblock class=spark-sql><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>spark-sql --packages org.apache.iceberg:iceberg-spark-runtime-3.2_2.12:1.2.1
</span></span></code></pre></div></codeblock><codeblock class=spark-shell><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>spark-shell --packages org.apache.iceberg:iceberg-spark-runtime-3.2_2.12:1.2.1
</span></span></code></pre></div></codeblock><codeblock class=pyspark><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>pyspark --packages org.apache.iceberg:iceberg-spark-runtime-3.2_2.12:1.2.1
</span></span></code></pre></div></codeblock></div><div class=info>If you want to include Iceberg in your Spark installation, add the Iceberg Spark runtime to Spark&rsquo;s <code>jars</code> folder.
You can download the runtime by visiting to the <a href=https://iceberg.apache.org/releases/>Releases</a> page.</div><h4 id=learn-more>Learn More</h4><p>Now that you&rsquo;re up an running with Iceberg and Spark, check out the <a href=../docs/latest/spark-ddl/>Iceberg-Spark docs</a> to learn more!</p></div></div></div></section></body><script src=https://iceberg.apache.org//js/jquery-1.11.0.js></script>
<script src=https://iceberg.apache.org//js/jquery.easing.min.js></script>
<script type=text/javascript src=https://iceberg.apache.org//js/search.js></script>
<script src=https://iceberg.apache.org//js/bootstrap.min.js></script>
<script src=https://iceberg.apache.org//js/iceberg-theme.js></script></html>